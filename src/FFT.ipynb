{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.5 MB 19.4 MB/s eta 0:00:01   |█████████▏                      | 9.9 MB 8.5 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.23.4)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.10.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "clips.npy exists.\n",
      "fft_log.npy exists.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/arrays/fft_log.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfft_log.npy exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m     fft \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/arrays/fft_log.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     fft \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m0\u001b[39m, window_num_per_clip, window_size))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:413\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode)\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py:755\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    768\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# データセット作成\n",
    "\n",
    "!pip install scipy\n",
    "\n",
    "window_size = 1024\n",
    "window_num_per_clip = 40\n",
    "clip_size = window_size * window_num_per_clip\n",
    "fft_sum_threshold = 50\n",
    "\n",
    "from scipy.io.wavfile import read\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def standardization(x):\n",
    "    ret = np.log(x + 1) / np.log(np.finfo(np.float32).max)\n",
    "    if (np.sum(ret) == 0):\n",
    "        return ret\n",
    "    else:\n",
    "        return ret / np.sum(ret)\n",
    "\n",
    "if os.path.isfile(\"../data/arrays/clips.npy\"):\n",
    "    print(\"clips.npy exists.\")\n",
    "    clips = np.load(\"../data/arrays/clips.npy\")\n",
    "else:\n",
    "    files = glob.glob(\"../data/wav44100/*\")\n",
    "    #files = [\"../data/wav44100/3DEmbodimentFromLines.wav\"]\n",
    "    raw_data_list = [read(file)[1] for file in files]\n",
    "\n",
    "    clips = np.zeros((0, clip_size), dtype=np.int16)\n",
    "    for raw_data in raw_data_list:\n",
    "        tmp = [raw_data[i:i + clip_size] for i in range(0, len(raw_data) - clip_size, clip_size)]\n",
    "        clips = np.vstack((clips, np.array(tmp)))\n",
    "    np.save(\"../data/arrays/clips\", clips)\n",
    "    \n",
    "    \n",
    "if os.path.isfile(\"../data/arrays/fft_log_normalized.npy\"):\n",
    "    print(\"fft_log_normalized.npy exists.\")\n",
    "    fft = np.load(\"../data/arrays/fft_log_normalized.npy\")\n",
    "else:\n",
    "    fft = np.zeros((0, window_num_per_clip, window_size))\n",
    "    num = 0\n",
    "    for clip in clips:\n",
    "        print(\"fft progress: clip \" + str(num))\n",
    "        \n",
    "        fft_tmp = np.zeros((0, window_size))\n",
    "        tmp = [clip[i:i + window_size] for i in range(0, len(clip) - window_size + 1, window_size)]\n",
    "        for tmp2 in tmp:\n",
    "            spectrum = np.abs(np.fft.fft(tmp2))\n",
    "            spectrum = standardization(spectrum)\n",
    "            fft_tmp = np.vstack((fft_tmp, spectrum))\n",
    "        fft = np.vstack((fft, fft_tmp.reshape(1, window_num_per_clip, window_size)))\n",
    "        num += 1\n",
    "\n",
    "    np.save(\"../data/arrays/fft_log_normalized\", fft)\n",
    "    \n",
    "print(\"clips.shape: \" + str(clips.shape))\n",
    "print(\"fft.shape: \" + str(fft.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとテストデータに分ける\n",
    "\n",
    "train_data_rate = 0.8\n",
    "\n",
    "x = np.concatenate([fft[:-1, :, :], fft[1:, 0, :].reshape(fft.shape[0] - 1, 1, fft.shape[2])], 1)\n",
    "\n",
    "p = np.random.permutation(len(x))\n",
    "x = x[p]\n",
    "clips = clips[p]\n",
    "\n",
    "x_train = x[:int(x.shape[0] * train_data_rate), :window_num_per_clip, :].reshape(int(x.shape[0] * train_data_rate), window_num_per_clip, window_size, 1)\n",
    "x_test = x[int(x.shape[0] * train_data_rate):, :window_num_per_clip, :].reshape(x.shape[0] - int(x.shape[0] * train_data_rate), window_num_per_clip, window_size, 1)\n",
    "y_train = x[:int(x.shape[0] * train_data_rate), window_num_per_clip, :]\n",
    "y_test = x[int(x.shape[0] * train_data_rate):, window_num_per_clip, :]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(np.max(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # 精度の履歴をプロット\n",
    "    plt.plot(history.history['accuracy'],\"o-\",label=\"accuracy\")\n",
    "    plt.plot(history.history['val_accuracy'],\"o-\",label=\"val_acc\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    " \n",
    "    # 損失の履歴をプロット\n",
    "    plt.plot(history.history['loss'],\"o-\",label=\"loss\",)\n",
    "    plt.plot(history.history['val_loss'],\"o-\",label=\"val_loss\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル作成\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "learning_rate = 0.0001\n",
    " \n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(3, (3, 1), activation='relu', input_shape=(window_num_per_clip - 1, window_size, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1024))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=learning_rate),metrics=['accuracy'])\n",
    "\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "model.save(\"../data/models/fft_batch256_e100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 遷移のプロット\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 楽曲の出力\n",
    "\n",
    "!pip install scikit-learn\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.io import wavfile\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"../data/models/fft_batch256_e100\")\n",
    "\n",
    "first_index = np.random.randint(0, len(x_test))\n",
    "predict_index = first_index\n",
    "out = np.zeros((0, ), dtype=np.int16)\n",
    "\n",
    "for i in range(10):\n",
    "    predict = model.predict(np.array([x_test[predict_index]]))\n",
    "    \n",
    "    index = 0\n",
    "    similar_index = 0\n",
    "    cos_sim = np.inf\n",
    "    for spectrum in x_test[:, 0:1, :, 0]:\n",
    "        tmp_sim = cosine_similarity(predict, spectrum) \n",
    "        if cos_sim > tmp_sim:\n",
    "            cos_sim = tmp_sim\n",
    "            similar_index = index\n",
    "        index += 1\n",
    "    \n",
    "    print(similar_index)\n",
    "    \n",
    "    predict_index = similar_index\n",
    "    out = np.hstack((out, clips[predict_index + int(x.shape[0] * train_data_rate)]))\n",
    "    \n",
    "wavfile.write(\"../data/out/fft_out_1.wav\", 44100, out)\n",
    "\n",
    "first_index = np.random.randint(0, len(x_test))\n",
    "predict_index = first_index\n",
    "out = np.zeros((0, ), dtype=np.int16)\n",
    "\n",
    "for i in range(10):\n",
    "    predict = model.predict(np.array([x_test[predict_index]]))\n",
    "    \n",
    "    index = 0\n",
    "    similar_index = 0\n",
    "    cos_sim = np.inf\n",
    "    for spectrum in x_test[:, 0:1, :, 0]:\n",
    "        tmp_sim = cosine_similarity(predict, spectrum) \n",
    "        if cos_sim > tmp_sim:\n",
    "            cos_sim = tmp_sim\n",
    "            similar_index = index\n",
    "        index += 1\n",
    "    \n",
    "    print(similar_index)\n",
    "    \n",
    "    predict_index = similar_index\n",
    "    out = np.hstack((out, clips[predict_index + int(x.shape[0] * train_data_rate)]))\n",
    "    \n",
    "wavfile.write(\"../data/out/fft_out_2.wav\", 44100, out)\n",
    "\n",
    "first_index = np.random.randint(0, len(x_test))\n",
    "predict_index = first_index\n",
    "out = np.zeros((0, ), dtype=np.int16)\n",
    "\n",
    "for i in range(10):\n",
    "    predict = model.predict(np.array([x_test[predict_index]]))\n",
    "    \n",
    "    index = 0\n",
    "    similar_index = 0\n",
    "    cos_sim = np.inf\n",
    "    for spectrum in x_test[:, 0:1, :, 0]:\n",
    "        tmp_sim = cosine_similarity(predict, spectrum) \n",
    "        if cos_sim > tmp_sim:\n",
    "            cos_sim = tmp_sim\n",
    "            similar_index = index\n",
    "        index += 1\n",
    "    \n",
    "    print(similar_index)\n",
    "    \n",
    "    predict_index = similar_index\n",
    "    out = np.hstack((out, clips[predict_index + int(x.shape[0] * train_data_rate)]))\n",
    "    \n",
    "wavfile.write(\"../data/out/fft_out_3.wav\", 44100, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
