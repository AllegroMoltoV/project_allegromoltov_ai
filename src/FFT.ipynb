{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.23.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [153], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m                 spectrum \u001b[38;5;241m=\u001b[39m softmax(spectrum)\n\u001b[1;32m     43\u001b[0m             fft_tmp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((fft_tmp, spectrum))\n\u001b[0;32m---> 44\u001b[0m         fft \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfft_tmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_num_per_clip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/arrays/fft\u001b[39m\u001b[38;5;124m\"\u001b[39m, fft)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(fft\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# データセット作成\n",
    "\n",
    "!pip install scipy\n",
    "\n",
    "window_size = 1024\n",
    "window_num_per_clip = 40\n",
    "clip_size = window_size * window_num_per_clip\n",
    "\n",
    "from scipy.io.wavfile import read\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def standardization(x):\n",
    "    return x / np.finfo(np.float64).max\n",
    "\n",
    "if os.path.isfile(\"../data/arrays/clips.npy\"):\n",
    "    print(\"clips.npy exists.\")\n",
    "    clips = np.load(\"../data/arrays/clips.npy\")\n",
    "else:\n",
    "    files = glob.glob(\"../data/wav44100/*\")\n",
    "    #files = [\"../data/wav44100/3DEmbodimentFromLines.wav\"]\n",
    "    raw_data_list = [read(file)[1] for file in files]\n",
    "\n",
    "    clips = np.zeros((0, clip_size), dtype=np.int16)\n",
    "    for raw_data in raw_data_list:\n",
    "        tmp = [raw_data[i:i + clip_size] for i in range(0, len(raw_data) - clip_size, clip_size)]\n",
    "        clips = np.vstack((clips, np.array(tmp)))\n",
    "    np.save(\"../data/arrays/clips\", clips)\n",
    "    \n",
    "if os.path.isfile(\"../data/arrays/fft.npy\"):\n",
    "    print(\"fft.npy exists.\")\n",
    "    fft = np.load(\"../data/arrays/fft.npy\")\n",
    "else:\n",
    "    fft = np.zeros((0, window_num_per_clip, window_size))\n",
    "    for clip in clips:\n",
    "        fft_tmp = np.zeros((0, window_size))\n",
    "        tmp = [clip[i:i + window_size] for i in range(0, len(clip) - window_size + 1, window_size)]\n",
    "        for tmp2 in tmp:\n",
    "            spectrum = np.abs(np.fft.fft(tmp2))\n",
    "            if np.max(spectrum) != 0:\n",
    "                spectrum = softmax(spectrum)\n",
    "            fft_tmp = np.vstack((fft_tmp, spectrum))\n",
    "        fft = np.vstack((fft, fft_tmp.reshape(1, window_num_per_clip, window_size)))\n",
    "\n",
    "    np.save(\"../data/arrays/fft\", fft)\n",
    "\n",
    "print(fft.shape)\n",
    "print(type(fft[0][0][0]))\n",
    "print(clips.shape)\n",
    "\n",
    "print(fft[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとテストデータに分ける\n",
    "\n",
    "train_data_rate = 0.8\n",
    "\n",
    "p = np.random.permutation(len(fft))\n",
    "fft = fft[p]\n",
    "clips = clips[p]\n",
    "\n",
    "x_train = fft[:int(fft.shape[0] * train_data_rate), :, :].reshape((x_train.shape[0], clip_size))\n",
    "x_test = fft[int(fft.shape[0] * train_data_rate):-1, :, :].reshape((x_test.shape[0], clip_size))\n",
    "y_train = fft[1:int(fft.shape[0] * train_data_rate) + 1, 0, :]\n",
    "y_test = fft[int(fft.shape[0] * train_data_rate) + 1:, 0, :]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(np.max(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # 精度の履歴をプロット\n",
    "    plt.plot(history.history['accuracy'],\"o-\",label=\"accuracy\")\n",
    "    plt.plot(history.history['val_accuracy'],\"o-\",label=\"val_acc\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    " \n",
    "    # 損失の履歴をプロット\n",
    "    plt.plot(history.history['loss'],\"o-\",label=\"loss\",)\n",
    "    plt.plot(history.history['val_loss'],\"o-\",label=\"val_loss\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル作成\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    " \n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(units=512,input_dim=clip_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=512,input_dim=clip_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1024))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 遷移のプロット\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 楽曲の出力\n",
    "\n",
    "!pip install scikit-learn\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.io import wavfile\n",
    "\n",
    "first_index = 1000\n",
    "predict_index = first_index\n",
    "out = np.zeros((0, ), dtype=np.int16)\n",
    "\n",
    "for i in range(10):\n",
    "    predict = model.predict(fft[predict_index].reshape(1, clip_size))\n",
    "    \n",
    "    index = 0\n",
    "    similar_index = 0\n",
    "    cos_sim = np.inf\n",
    "    for spectrum in fft[:, 0:1, :]:\n",
    "        tmp_sim = cosine_similarity(predict, spectrum) \n",
    "        if cos_sim > tmp_sim:\n",
    "            cos_sim = tmp_sim\n",
    "            similar_index = index\n",
    "        index += 1\n",
    "    \n",
    "    print(similar_index)\n",
    "    \n",
    "    predict_index = similar_index\n",
    "    out = np.hstack((out, clips[predict_index]))\n",
    "    \n",
    "wavfile.write(\"../data/out/fft_out_1.wav\", 44100, out)\n",
    "\n",
    "first_index = 2000\n",
    "predict_index = first_index\n",
    "out = np.zeros((0, ), dtype=np.int16)\n",
    "\n",
    "for i in range(10):\n",
    "    predict = model.predict(fft[predict_index].reshape(1, clip_size))\n",
    "    \n",
    "    index = 0\n",
    "    similar_index = 0\n",
    "    cos_sim = np.inf\n",
    "    for spectrum in fft[:, 0:1, :]:\n",
    "        tmp_sim = cosine_similarity(predict, spectrum) \n",
    "        if cos_sim > tmp_sim:\n",
    "            cos_sim = tmp_sim\n",
    "            similar_index = index\n",
    "        index += 1\n",
    "    \n",
    "    print(similar_index)\n",
    "    \n",
    "    predict_index = similar_index\n",
    "    out = np.hstack((out, clips[predict_index]))\n",
    "    \n",
    "wavfile.write(\"../data/out/fft_out_2.wav\", 44100, out)\n",
    "\n",
    "first_index = 3000\n",
    "predict_index = first_index\n",
    "out = np.zeros((0, ), dtype=np.int16)\n",
    "\n",
    "for i in range(10):\n",
    "    predict = model.predict(fft[predict_index].reshape(1, clip_size))\n",
    "    \n",
    "    index = 0\n",
    "    similar_index = 0\n",
    "    cos_sim = np.inf\n",
    "    for spectrum in fft[:, 0:1, :]:\n",
    "        tmp_sim = cosine_similarity(predict, spectrum) \n",
    "        if cos_sim > tmp_sim:\n",
    "            cos_sim = tmp_sim\n",
    "            similar_index = index\n",
    "        index += 1\n",
    "    \n",
    "    print(similar_index)\n",
    "    \n",
    "    predict_index = similar_index\n",
    "    out = np.hstack((out, clips[predict_index]))\n",
    "    \n",
    "wavfile.write(\"../data/out/fft_out_3.wav\", 44100, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
