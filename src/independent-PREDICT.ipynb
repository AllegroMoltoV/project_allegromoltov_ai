{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/allegro/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Reading package lists... Done\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "/bin/bash: /home/allegro/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "/bin/bash: /home/allegro/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: scipy in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scipy) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "# 環境構築\n",
    "\n",
    "!apt-get update\n",
    "!apt-get install -y libsndfile1-dev\n",
    "!pip install scipy\n",
    "!pip install scikit-learn\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clips 作成\n",
    "\n",
    "SAMPLING_RATE = 44100 # 変更不可\n",
    "\n",
    "clip_size = 81920 # 楽曲を再構築するパーツ1つあたりの大きさ\n",
    "step_size = 20480 # clip をずらすときの大きさ\n",
    "window_size = 10240 # CQT_CHROMA を取得するのに使用するサンプル数\n",
    "hop_size = 640 # window をずらすときの大きさ\n",
    "\n",
    "from scipy.io.wavfile import read, write\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import sys\n",
    "\n",
    "if os.path.isfile(\"../data/out/clips4predict.wav\"):\n",
    "    print(\"../data/out/clips4predict.wav exists.\")\n",
    "    files = [\"../data/out/clips4predict.wav\"]\n",
    "else:\n",
    "    # clips.npy をもとにデータを作成する \n",
    "    if os.path.isfile(\"../data/arrays/clips4predict.npy\"):\n",
    "        print(\"loading ../data/arrays/clips4predict.npy ...\")\n",
    "        clips = np.load(\"../data/arrays/clips4predict.npy\")\n",
    "        print(\"creating ../data/out/clips4predict.wav ...\")\n",
    "        write(\"../data/out/clips4predict.wav\", SAMPLING_RATE, clips.reshape((clips.shape[0] * clips.shape[1], )))\n",
    "        files = [\"../data/out/clips4predict.wav\"]\n",
    "        \n",
    "    # clips,npy がないとき /data/wav44100 内の WAV ファイルを参照する\n",
    "    else:\n",
    "        files = glob.glob(\"../data/wav4predict/*.wav\")\n",
    "        #files = [\"../data/wav44100/3DEmbodimentFromLines.wav\"] # デバッグ用 \n",
    "        \n",
    "if len(files) == 0:\n",
    "    print(\"WAV ファイルが見つかりませんでした。\")\n",
    "    sys.exit(1)\n",
    "        \n",
    "clips_filename = \"../data/arrays/c\" + str(clip_size) + \"_s\" + str(step_size) + \"_f32_clips4predict\"\n",
    "\n",
    "if os.path.isfile(clips_filename + \".npy\"):\n",
    "    print(\"loading \" + clips_filename + \".npy ...\")\n",
    "    clips = np.load(clips_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + clips_filename + \".npy ...\")\n",
    "    raw_data_list = [librosa.load(file, sr=SAMPLING_RATE)[0] for file in files] # 左の音だけ使う\n",
    "\n",
    "    clips = np.zeros((0, clip_size), dtype=np.float32)\n",
    "    for raw_data in raw_data_list:\n",
    "        tmp = [raw_data[i:i + clip_size] for i in range(0, len(raw_data) - clip_size, step_size)]\n",
    "        clips = np.vstack((clips, np.array(tmp)))\n",
    "    np.save(clips_filename, clips)\n",
    "\n",
    "print(\"The clip array has \" + str(clips.shape[0]) + \" clips.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cqt 作成\n",
    "\n",
    "n_bins = 84\n",
    "\n",
    "cqt_filename = clips_filename + \"_w\" + str(window_size) + \"_h\" + str(hop_size) + \"_cqts4predict\"\n",
    "\n",
    "if os.path.isfile(cqt_filename + \".npy\"):\n",
    "    print(\"loading \" + cqt_filename + \".npy ...\")\n",
    "    cqts = np.load(cqt_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + cqt_filename + \".npy ...\")\n",
    "    num = 0\n",
    "    for clip in clips:\n",
    "        print(\"cqt progress: clip \" + str(num + 1) + \" / \" + str(len(clips)))\n",
    "        \n",
    "        tmp_cqt = librosa.cqt(clip, sr=SAMPLING_RATE, hop_length=hop_size, n_bins=n_bins)\n",
    "        tmp_cqt = tmp_cqt.reshape((1, tmp_cqt.shape[0], tmp_cqt.shape[1]))\n",
    "        \n",
    "        if num == 0:\n",
    "            cqts = tmp_cqt\n",
    "        else:\n",
    "            cqts = np.vstack((cqts, tmp_cqt))\n",
    "            \n",
    "        num += 1\n",
    "\n",
    "    np.save(cqt_filename, cqts)\n",
    "    \n",
    "print(\"The cqt array has \" + str(cqts.shape[0]) + \" cqts.\")\n",
    "print(\"cqts.shape: \" + str(cqts.shape))\n",
    "print(\"Type(cqts[0][0][0]): \" + str(type(cqts[0][0][0])))\n",
    "print(\"np.max(cqts[0][0]): \" + str(np.max(cqts[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cqt_choroma 作成\n",
    "\n",
    "def Preprocessing(array):\n",
    "    array = np.abs(array)\n",
    "    array = np.log(array + 1)\n",
    "    array = array / np.log(np.finfo(np.float32).max)\n",
    "    array = array.T\n",
    "    return array\n",
    "\n",
    "cqt_chroma_filename = clips_filename + \"_w\" + str(window_size) + \"_h\" + str(hop_size) + \"_cqt_chromas4predict\"\n",
    "\n",
    "if os.path.isfile(cqt_chroma_filename + \".npy\"):\n",
    "    print(\"loading \" + cqt_chroma_filename + \".npy ...\")\n",
    "    cqt_chromas= np.load(cqt_chroma_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + cqt_chroma_filename + \".npy ...\")\n",
    "    num = 0\n",
    "    for cqt in cqts:\n",
    "        print(\"cqt_chroma progress: clip \" + str(num + 1) + \" / \" + str(len(cqts)))\n",
    "        \n",
    "        tmp_cqt_chroma = librosa.feature.chroma_cqt(C=cqt, sr=SAMPLING_RATE)\n",
    "        tmp_cqt_chroma = Preprocessing(tmp_cqt_chroma)\n",
    "        tmp_cqt_chroma = tmp_cqt_chroma.reshape((1, tmp_cqt_chroma.shape[0], tmp_cqt_chroma.shape[1]))\n",
    "        \n",
    "        if num == 0:\n",
    "            cqt_chromas = tmp_cqt_chroma\n",
    "        else:\n",
    "            cqt_chromas = np.vstack((cqt_chromas, tmp_cqt_chroma))\n",
    "            \n",
    "        num += 1\n",
    "\n",
    "    np.save(cqt_chroma_filename, cqt_chromas)\n",
    "    \n",
    "print(\"The cqt_chroma array has \" + str(cqt_chromas.shape[0]) + \" cqt_chromas.\")\n",
    "print(\"cqt_chromas.shape: \" + str(cqt_chromas.shape)) # clip 番号、window 番号、 chroma 番号 になる\n",
    "print(\"Type(cqt_chromas[0][0][0]): \" + str(type(cqt_chromas[0][0][0])))\n",
    "print(\"np.max(cqt_chromas[0][0]): \" + str(np.max(cqt_chromas[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_norm 作成\n",
    "\n",
    "num_divide = 8\n",
    "\n",
    "max_norm_filename = clips_filename + \"_d\" + str(num_divide) + \"_max_norms4predict\"\n",
    "\n",
    "if os.path.isfile(max_norm_filename + \".npy\"):\n",
    "    print(\"loading \" + max_norm_filename + \".npy ...\")\n",
    "    max_norms= np.load(max_norm_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + max_norm_filename + \".npy ...\")\n",
    "    num = 0\n",
    "    for clip in clips:\n",
    "        print(\"max_norm progress: clip \" + str(num + 1) + \" / \" + str(len(clips)))\n",
    "        max_norm = [np.max(clip[int((i / num_divide) * len(clip)):int(((i + 1) / num_divide) * len(clip))] ** 2) for i in range(num_divide)]\n",
    "    \n",
    "        if num == 0:\n",
    "            max_norms = np.array(max_norm)\n",
    "        else:\n",
    "            max_norms = np.vstack((max_norms, np.array(max_norm)))\n",
    "        num += 1\n",
    "        \n",
    "    np.save(max_norm_filename, max_norms)\n",
    "    \n",
    "print(\"The max_norm array has \" + str(max_norms.shape[0]) + \" max_norms.\")\n",
    "print(\"max_norms.shape: \" + str(max_norms.shape))\n",
    "print(\"Type(max_norms[0][0]): \" + str(type(max_norms[0][0])))\n",
    "print(\"np.max(max_norms[0]): \" + str(np.max(max_norms[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとテストデータに分ける\n",
    "\n",
    "def normalize(array):\n",
    "    if (np.sum(array) == 0):\n",
    "        return array\n",
    "    else:\n",
    "        return array / np.sum(array)\n",
    "    \n",
    "cqt_chroma_sum_threshold = 0.01 # 次の window の sum が閾値に満たないときに除外します\n",
    "test_data_rate = 0.1\n",
    "\n",
    "window_num_per_clip = cqt_chromas.shape[1]\n",
    "\n",
    "cqt_chromas = np.array([np.hstack((cqt_chromas[i], np.repeat(np.array([max_norms[i]]), cqt_chromas.shape[1], axis=0))) for i in range(len(max_norms))])\n",
    "cqt_chromas = np.concatenate([cqt_chromas[:-1, :, :], cqt_chromas[1:, 0, :].reshape(cqt_chromas.shape[0] - 1, 1, cqt_chromas.shape[2])], 1)\n",
    "\n",
    "p = np.random.permutation(len(cqt_chromas))\n",
    "cqt_chromas = cqt_chromas[p]\n",
    "clips = clips[p]\n",
    "\n",
    "x = np.delete(cqt_chromas, np.where(np.sum(cqt_chromas[:,-1,:], axis=1) < cqt_chroma_sum_threshold)[0], axis=0)\n",
    "\n",
    "x_test = x[:int(x.shape[0] * test_data_rate), :window_num_per_clip, :].reshape(int(x.shape[0] * test_data_rate), window_num_per_clip, x.shape[2], 1)\n",
    "x_train = x[int(x.shape[0] * test_data_rate):, :window_num_per_clip, :].reshape(x.shape[0] - int(x.shape[0] * test_data_rate), window_num_per_clip, x.shape[2], 1)\n",
    "\n",
    "y = np.array([x[:, window_num_per_clip, i] for i in range(x.shape[2])])\n",
    "y_maxs = np.max(y, axis=1)\n",
    "\n",
    "y_tests =  np.array([x[:int(x.shape[0] * test_data_rate), window_num_per_clip, i] / y_maxs[i] for i in range(x.shape[2])])\n",
    "y_trains = np.array([x[int(x.shape[0] * test_data_rate):, window_num_per_clip, i] / y_maxs[i] for i in range(x.shape[2])])\n",
    "\n",
    "print(\"x_train.shape: \" + str(x_train.shape))\n",
    "print(\"x_test.shape: \" + str(x_test.shape))\n",
    "print(\"y_trains.shape: \" + str(y_trains.shape))\n",
    "print(\"y_tests.shape: \" + str(y_tests.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 楽曲の出力\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.models import load_model\n",
    "import soundfile as sf\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "def add_fade(x, fadetime, sr):\n",
    "    ft_len = int(fadetime*sr)\n",
    "    r = np.arange(0, ft_len)*np.pi/ft_len\n",
    "    w_fo = (0.5+0.5*np.cos(r))**0.5\n",
    "    w_fi = (0.5-0.5*np.cos(r))**0.5\n",
    "    \n",
    "    x[0:ft_len]        *= w_fi\n",
    "    x[clip_size-ft_len::] *= w_fo\n",
    "    return x\n",
    "\n",
    "def gen_xfade(x_pre, x_next, fadetime, sr):\n",
    "    ft_len = int(fadetime*sr)\n",
    "    if x_pre is None:\n",
    "        xfade = x_next\n",
    "    else:\n",
    "        x_pre_begin = x_pre[:x_pre.shape[0] - ft_len]\n",
    "        x_pre_end = x_pre[x_pre.shape[0] - ft_len:]\n",
    "        x_pre_len = clip_size\n",
    "        x_next_len = clip_size\n",
    "        x_pre_len -= ft_len\n",
    "        x_next_len -= ft_len\n",
    "        xfade = np.concatenate((x_pre_begin, np.concatenate((x_pre_end, np.zeros(x_next_len))) + x_next))\n",
    "    return xfade\n",
    "\n",
    "def create_music_consider_weights(fname):\n",
    "    first_index = np.random.randint(0, len(cqt_chromas))\n",
    "    predict_index = first_index\n",
    "    out = None\n",
    "    \n",
    "    for i in range(num_clips):\n",
    "        print(\"-- generate \" + str(i + 1) + \" / \" + str(num_clips))\n",
    "        predict_vec = np.zeros((0, ))\n",
    "        for i in range(x.shape[2]):\n",
    "            predict = models[i].predict(np.array([cqt_chromas[predict_index, :-1]]))[0] * y_maxs[i]\n",
    "            predict_vec = np.hstack((predict_vec, predict))\n",
    "        predict_chroma = predict_vec[:len(predict_vec)-num_divide]\n",
    "        predict_rhythm = predict_vec[len(predict_vec)-num_divide:]\n",
    "\n",
    "        index = 0\n",
    "        similar_index = 0\n",
    "        score = -1 - rhythm_weight\n",
    "        chroma_score = 0\n",
    "        rhythm_score = 0\n",
    "        for cqt_chroma in cqt_chromas[:, 0]:\n",
    "            cqt_chroma_chroma = cqt_chroma[:len(cqt_chroma)-num_divide]\n",
    "            cqt_chroma_rhythm = cqt_chroma[len(cqt_chroma)-num_divide:]\n",
    "            tmp_chroma_score = cosine_similarity(np.array([predict_chroma]), np.array([cqt_chroma_chroma]))\n",
    "            tmp_rhythm_score = cosine_similarity(np.array([predict_rhythm]), np.array([cqt_chroma_rhythm]))\n",
    "            tmp_score = tmp_chroma_score + rhythm_weight * tmp_rhythm_score\n",
    "            if tmp_score > score:\n",
    "                score = tmp_score\n",
    "                similar_index = index\n",
    "            index += 1\n",
    "\n",
    "        print(\"score: \" + str(score))\n",
    "        print(\"predict_vec: \" + str(predict_vec))\n",
    "        print(\"cqt_chromas[similar_index]: \" + str(cqt_chromas[similar_index, 0]))\n",
    "        print(\"similar_index: \" + str(similar_index))\n",
    "        print(\"--\")\n",
    "\n",
    "        predict_index = similar_index\n",
    "\n",
    "        tmp = add_fade(clips[predict_index], 0.1, SAMPLING_RATE)\n",
    "        out = gen_xfade(out, tmp, 0.1, SAMPLING_RATE)\n",
    "        \n",
    "    sf.write(fname, out, SAMPLING_RATE, subtype=\"PCM_16\")\n",
    "\n",
    "rhythm_weight = 0.5\n",
    "\n",
    "models = []\n",
    "for i in range(x.shape[2]):\n",
    "    model_name = \"independent_\" + data_name + \"_batch\" + str(batch_size) + \"_e\" + str(epochs) + \"_\" + str(i)\n",
    "    \n",
    "    models.append(load_model(\"../data/models/\" + model_name))\n",
    "\n",
    "file_name = \"out_\" + \"independent_\" + data_name + \"_batch\" + str(batch_size) + \"_e\" + str(epochs) + \"_rw\" + str(rhythm_weight).replace('.', '_') + \"_PREDICT\"\n",
    "num_clips = 100\n",
    "\n",
    "for i in range(10):\n",
    "    fname = \"../data/out/\" + file_name + \"_track\" + str(i) + \".wav\"\n",
    "    print(\"creating \" + fname + \" ...\")\n",
    "    create_music_consider_weights(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
