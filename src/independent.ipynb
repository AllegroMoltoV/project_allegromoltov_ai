{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/allegro/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Reading package lists... Done\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "/bin/bash: /home/allegro/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "/bin/bash: /home/allegro/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: scipy in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scipy) (1.23.5)\n",
      "/bin/bash: /home/allegro/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: scikit-learn in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "/bin/bash: /home/allegro/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: librosa in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.23.5)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (0.3.3)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.0.4)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (4.5.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.2.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: setuptools in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (65.6.3)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from pooch>=1.0->librosa) (2.28.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from pooch>=1.0->librosa) (3.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from pooch>=1.0->librosa) (23.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "# 環境構築\n",
    "\n",
    "!apt-get update\n",
    "!apt-get install -y libsndfile1-dev\n",
    "!pip install scipy\n",
    "!pip install scikit-learn\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/out/clips.wav exists.\n",
      "loading ../data/arrays/c81920_s20480_f32_clips.npy ...\n",
      "The clip array has 57148 clips.\n"
     ]
    }
   ],
   "source": [
    "# clips 作成\n",
    "\n",
    "SAMPLING_RATE = 44100 # 変更不可\n",
    "\n",
    "clip_size = 81920 # 楽曲を再構築するパーツ1つあたりの大きさ\n",
    "step_size = 20480 # clip をずらすときの大きさ\n",
    "window_size = 10240 # CQT_CHROMA を取得するのに使用するサンプル数\n",
    "hop_size = 640 # window をずらすときの大きさ\n",
    "\n",
    "from scipy.io.wavfile import read, write\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import sys\n",
    "\n",
    "if os.path.isfile(\"../data/out/clips.wav\"):\n",
    "    print(\"../data/out/clips.wav exists.\")\n",
    "    files = [\"../data/out/clips.wav\"]\n",
    "else:\n",
    "    # clips.npy をもとにデータを作成する \n",
    "    if os.path.isfile(\"../data/arrays/clips.npy\"):\n",
    "        print(\"loading ../data/arrays/clips.npy ...\")\n",
    "        clips = np.load(\"../data/arrays/clips.npy\")\n",
    "        print(\"creating ../data/out/clips.wav ...\")\n",
    "        write(\"../data/out/clips.wav\", SAMPLING_RATE, clips.reshape((clips.shape[0] * clips.shape[1], )))\n",
    "        files = [\"../data/out/clips.wav\"]\n",
    "        \n",
    "    # clips,npy がないとき /data/wav44100 内の WAV ファイルを参照する\n",
    "    else:\n",
    "        files = glob.glob(\"../data/wav44100/*.wav\")\n",
    "        #files = [\"../data/wav44100/3DEmbodimentFromLines.wav\"] # デバッグ用 \n",
    "        \n",
    "if len(files) == 0:\n",
    "    print(\"WAV ファイルが見つかりませんでした。\")\n",
    "    sys.exit(1)\n",
    "        \n",
    "clips_filename = \"../data/arrays/c\" + str(clip_size) + \"_s\" + str(step_size) + \"_f32_clips\"\n",
    "\n",
    "if os.path.isfile(clips_filename + \".npy\"):\n",
    "    print(\"loading \" + clips_filename + \".npy ...\")\n",
    "    clips = np.load(clips_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + clips_filename + \".npy ...\")\n",
    "    raw_data_list = [librosa.load(file, sr=SAMPLING_RATE)[0] for file in files] # 左の音だけ使う\n",
    "\n",
    "    clips = np.zeros((0, clip_size), dtype=np.float32)\n",
    "    for raw_data in raw_data_list:\n",
    "        tmp = [raw_data[i:i + clip_size] for i in range(0, len(raw_data) - clip_size, step_size)]\n",
    "        clips = np.vstack((clips, np.array(tmp)))\n",
    "    np.save(clips_filename, clips)\n",
    "\n",
    "print(\"The clip array has \" + str(clips.shape[0]) + \" clips.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../data/arrays/c81920_s20480_f32_clips_w10240_h640_cqts.npy ...\n",
      "The cqt array has 57148 cqts.\n",
      "cqts.shape: (57148, 84, 129)\n",
      "Type(cqts[0][0][0]): <class 'numpy.complex64'>\n",
      "np.max(cqts[0][0]): (0.021538047+0.007131239j)\n"
     ]
    }
   ],
   "source": [
    "# cqt 作成\n",
    "\n",
    "n_bins = 84\n",
    "\n",
    "cqt_filename = clips_filename + \"_w\" + str(window_size) + \"_h\" + str(hop_size) + \"_cqts\"\n",
    "\n",
    "if os.path.isfile(cqt_filename + \".npy\"):\n",
    "    print(\"loading \" + cqt_filename + \".npy ...\")\n",
    "    cqts = np.load(cqt_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + cqt_filename + \".npy ...\")\n",
    "    num = 0\n",
    "    for clip in clips:\n",
    "        print(\"cqt progress: clip \" + str(num + 1) + \" / \" + str(len(clips)))\n",
    "        \n",
    "        tmp_cqt = librosa.cqt(clip, sr=SAMPLING_RATE, hop_length=hop_size, n_bins=n_bins)\n",
    "        tmp_cqt = tmp_cqt.reshape((1, tmp_cqt.shape[0], tmp_cqt.shape[1]))\n",
    "        \n",
    "        if num == 0:\n",
    "            cqts = tmp_cqt\n",
    "        else:\n",
    "            cqts = np.vstack((cqts, tmp_cqt))\n",
    "            \n",
    "        num += 1\n",
    "\n",
    "    np.save(cqt_filename, cqts)\n",
    "    \n",
    "print(\"The cqt array has \" + str(cqts.shape[0]) + \" cqts.\")\n",
    "print(\"cqts.shape: \" + str(cqts.shape))\n",
    "print(\"Type(cqts[0][0][0]): \" + str(type(cqts[0][0][0])))\n",
    "print(\"np.max(cqts[0][0]): \" + str(np.max(cqts[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../data/arrays/c81920_s20480_f32_clips_w10240_h640_cqt_chromas.npy ...\n",
      "The cqt_chroma array has 57148 cqt_chromas.\n",
      "cqt_chromas.shape: (57148, 129, 12)\n",
      "Type(cqt_chromas[0][0][0]): <class 'numpy.float32'>\n",
      "np.max(cqt_chromas[0][0]): 0.0078125\n"
     ]
    }
   ],
   "source": [
    "# cqt_choroma 作成\n",
    "\n",
    "def Preprocessing(array):\n",
    "    array = np.abs(array)\n",
    "    array = np.log(array + 1)\n",
    "    array = array / np.log(np.finfo(np.float32).max)\n",
    "    array = array.T\n",
    "    return array\n",
    "\n",
    "cqt_chroma_filename = clips_filename + \"_w\" + str(window_size) + \"_h\" + str(hop_size) + \"_cqt_chromas\"\n",
    "\n",
    "if os.path.isfile(cqt_chroma_filename + \".npy\"):\n",
    "    print(\"loading \" + cqt_chroma_filename + \".npy ...\")\n",
    "    cqt_chromas= np.load(cqt_chroma_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + cqt_chroma_filename + \".npy ...\")\n",
    "    num = 0\n",
    "    for cqt in cqts:\n",
    "        print(\"cqt_chroma progress: clip \" + str(num + 1) + \" / \" + str(len(cqts)))\n",
    "        \n",
    "        tmp_cqt_chroma = librosa.feature.chroma_cqt(C=cqt, sr=SAMPLING_RATE)\n",
    "        tmp_cqt_chroma = Preprocessing(tmp_cqt_chroma)\n",
    "        tmp_cqt_chroma = tmp_cqt_chroma.reshape((1, tmp_cqt_chroma.shape[0], tmp_cqt_chroma.shape[1]))\n",
    "        \n",
    "        if num == 0:\n",
    "            cqt_chromas = tmp_cqt_chroma\n",
    "        else:\n",
    "            cqt_chromas = np.vstack((cqt_chromas, tmp_cqt_chroma))\n",
    "            \n",
    "        num += 1\n",
    "\n",
    "    np.save(cqt_chroma_filename, cqt_chromas)\n",
    "    \n",
    "print(\"The cqt_chroma array has \" + str(cqt_chromas.shape[0]) + \" cqt_chromas.\")\n",
    "print(\"cqt_chromas.shape: \" + str(cqt_chromas.shape)) # clip 番号、window 番号、 chroma 番号 になる\n",
    "print(\"Type(cqt_chromas[0][0][0]): \" + str(type(cqt_chromas[0][0][0])))\n",
    "print(\"np.max(cqt_chromas[0][0]): \" + str(np.max(cqt_chromas[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../data/arrays/c81920_s20480_f32_clips_d4_max_norms.npy ...\n",
      "The max_norm array has 57148 max_norms.\n",
      "max_norms.shape: (57148, 4)\n",
      "Type(max_norms[0][0]): <class 'numpy.float32'>\n",
      "np.max(max_norms[0]): 0.0179649\n"
     ]
    }
   ],
   "source": [
    "# max_norm 作成\n",
    "\n",
    "num_divide = 4\n",
    "\n",
    "max_norm_filename = clips_filename + \"_d\" + str(num_divide) + \"_max_norms\"\n",
    "\n",
    "if os.path.isfile(max_norm_filename + \".npy\"):\n",
    "    print(\"loading \" + max_norm_filename + \".npy ...\")\n",
    "    max_norms= np.load(max_norm_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + max_norm_filename + \".npy ...\")\n",
    "    num = 0\n",
    "    for clip in clips:\n",
    "        print(\"max_norm progress: clip \" + str(num + 1) + \" / \" + str(len(clips)))\n",
    "        max_norm = [np.max(clip[int((i / num_divide) * len(clip)):int(((i + 1) / num_divide) * len(clip))] ** 2) for i in range(num_divide)]\n",
    "    \n",
    "        if num == 0:\n",
    "            max_norms = np.array(max_norm)\n",
    "        else:\n",
    "            max_norms = np.vstack((max_norms, np.array(max_norm)))\n",
    "        num += 1\n",
    "        \n",
    "    np.save(max_norm_filename, max_norms)\n",
    "    \n",
    "print(\"The max_norm array has \" + str(max_norms.shape[0]) + \" max_norms.\")\n",
    "print(\"max_norms.shape: \" + str(max_norms.shape))\n",
    "print(\"Type(max_norms[0][0]): \" + str(type(max_norms[0][0])))\n",
    "print(\"np.max(max_norms[0]): \" + str(np.max(max_norms[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (51237, 129, 16, 1)\n",
      "x_test.shape: (5692, 129, 16, 1)\n",
      "y_trains.shape: (16, 51237)\n",
      "y_tests.shape: (16, 5692)\n"
     ]
    }
   ],
   "source": [
    "# 学習データとテストデータに分ける\n",
    "\n",
    "def normalize(array):\n",
    "    if (np.sum(array) == 0):\n",
    "        return array\n",
    "    else:\n",
    "        return array / np.sum(array)\n",
    "    \n",
    "cqt_chroma_sum_threshold = 0.01 # 次の window の sum が閾値に満たないときに除外します\n",
    "test_data_rate = 0.1\n",
    "weight = 0.01 # max_norm の重み\n",
    "\n",
    "window_num_per_clip = cqt_chromas.shape[1]\n",
    "\n",
    "cqt_chromas = np.array([np.hstack((cqt_chromas[i], np.repeat(np.array([max_norms[i]]), cqt_chromas.shape[1], axis=0) * weight)) for i in range(len(max_norms))])\n",
    "cqt_chromas = np.concatenate([cqt_chromas[:-1, :, :], cqt_chromas[1:, 0, :].reshape(cqt_chromas.shape[0] - 1, 1, cqt_chromas.shape[2])], 1)\n",
    "\n",
    "p = np.random.permutation(len(cqt_chromas))\n",
    "cqt_chromas = cqt_chromas[p]\n",
    "clips = clips[p]\n",
    "\n",
    "x = np.delete(cqt_chromas, np.where(np.sum(cqt_chromas[:,-1,:], axis=1) < cqt_chroma_sum_threshold)[0], axis=0)\n",
    "\n",
    "x_test = x[:int(x.shape[0] * test_data_rate), :window_num_per_clip, :].reshape(int(x.shape[0] * test_data_rate), window_num_per_clip, x.shape[2], 1)\n",
    "x_train = x[int(x.shape[0] * test_data_rate):, :window_num_per_clip, :].reshape(x.shape[0] - int(x.shape[0] * test_data_rate), window_num_per_clip, x.shape[2], 1)\n",
    "y_tests =  np.array([x[:int(x.shape[0] * test_data_rate), window_num_per_clip, i] for i in range(x.shape[2])])\n",
    "y_trains = np.array([x[int(x.shape[0] * test_data_rate):, window_num_per_clip, i] for i in range(x.shape[2])])\n",
    "\n",
    "print(\"x_train.shape: \" + str(x_train.shape))\n",
    "print(\"x_test.shape: \" + str(x_test.shape))\n",
    "print(\"y_trains.shape: \" + str(y_trains.shape))\n",
    "print(\"y_tests.shape: \" + str(y_tests.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # 精度の履歴をプロット\n",
    "    plt.plot(history.history['accuracy'],\"o-\",label=\"accuracy\")\n",
    "    plt.plot(history.history['val_accuracy'],\"o-\",label=\"val_acc\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    " \n",
    "    # 損失の履歴をプロット\n",
    "    plt.plot(history.history['loss'],\"o-\",label=\"loss\",)\n",
    "    plt.plot(history.history['val_loss'],\"o-\",label=\"val_loss\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 17:48:56.228883: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-11 17:48:56.558961: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-11 17:48:58.829416: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/allegro/miniconda3/lib/\n",
      "2023-03-11 17:48:58.833340: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/allegro/miniconda3/lib/\n",
      "2023-03-11 17:48:58.833356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-11 17:49:00.390825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 16, 256)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24576)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 17:49:00.538878: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 17:49:00.538916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 17:49:00.541042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-11 17:49:00.549540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 17:49:00.549590: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 17:49:00.549606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 17:49:07.619501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 17:49:07.620144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 17:49:07.620156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-11 17:49:07.620183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 17:49:07.620215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5424 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 63, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 30, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 14, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 6, 16, 256)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 63, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 30, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_16 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 63, 16, 32)       0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 63, 16, 32)        0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_44 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_44 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_45 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_46 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_48 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " max_pooling2d_53 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_56 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_60 (Conv2D)          (None, 127, 16, 32)       128       \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPoolin  (None, 63, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 63, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 61, 16, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPoolin  (None, 30, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 30, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 28, 16, 128)       24704     \n",
      "                                                                 \n",
      " max_pooling2d_62 (MaxPoolin  (None, 14, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 14, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 12, 16, 256)       98560     \n",
      "                                                                 \n",
      " max_pooling2d_63 (MaxPoolin  (None, 6, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 6, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 24577     \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,177\n",
      "Trainable params: 154,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデル作成\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, Input, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "models = []\n",
    "for i in range(x.shape[2]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Conv2D(32, (3, 1), activation=\"relu\", input_shape=(window_num_per_clip, cqt_chromas.shape[2], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64, (3, 1), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(128, (3, 1), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(256, (3, 1), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=1))\n",
    "    model.add(Activation('linear'))\n",
    "    model.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=learning_rate),metrics=['accuracy'])\n",
    "\n",
    "    model.build()\n",
    "    model.summary()\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 17:49:10.355779: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_15/dropout_60/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-03-11 17:49:13.117195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-11 17:49:16.962136: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-11 17:49:17.000536: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-11 17:49:17.000619: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:85] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-03-11 17:49:17.037345: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-11 17:49:17.037466: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-03-11 17:49:19.958954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 22s 13ms/step - loss: 9.7063e-06 - accuracy: 0.5016 - val_loss: 8.7361e-06 - val_accuracy: 0.4972\n",
      "Epoch 2/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6695e-06 - accuracy: 0.5016 - val_loss: 8.9393e-06 - val_accuracy: 0.4972\n",
      "Epoch 3/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6814e-06 - accuracy: 0.5016 - val_loss: 8.7021e-06 - val_accuracy: 0.4972\n",
      "Epoch 4/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7064e-06 - accuracy: 0.5016 - val_loss: 8.6795e-06 - val_accuracy: 0.4972\n",
      "Epoch 5/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6897e-06 - accuracy: 0.5016 - val_loss: 8.7134e-06 - val_accuracy: 0.4972\n",
      "Epoch 6/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7070e-06 - accuracy: 0.5016 - val_loss: 8.7259e-06 - val_accuracy: 0.4972\n",
      "Epoch 7/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6824e-06 - accuracy: 0.5016 - val_loss: 8.7087e-06 - val_accuracy: 0.4972\n",
      "Epoch 8/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7172e-06 - accuracy: 0.5016 - val_loss: 8.8598e-06 - val_accuracy: 0.4972\n",
      "Epoch 9/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6942e-06 - accuracy: 0.5016 - val_loss: 8.6795e-06 - val_accuracy: 0.4972\n",
      "Epoch 10/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7129e-06 - accuracy: 0.5016 - val_loss: 8.7199e-06 - val_accuracy: 0.4972\n",
      "Epoch 11/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7063e-06 - accuracy: 0.5016 - val_loss: 8.6796e-06 - val_accuracy: 0.4972\n",
      "Epoch 12/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7091e-06 - accuracy: 0.5016 - val_loss: 8.6806e-06 - val_accuracy: 0.4972\n",
      "Epoch 13/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6914e-06 - accuracy: 0.5016 - val_loss: 9.0553e-06 - val_accuracy: 0.4972\n",
      "Epoch 14/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7099e-06 - accuracy: 0.5016 - val_loss: 9.3146e-06 - val_accuracy: 0.4972\n",
      "Epoch 15/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7330e-06 - accuracy: 0.5016 - val_loss: 8.7508e-06 - val_accuracy: 0.4972\n",
      "Epoch 16/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7002e-06 - accuracy: 0.5016 - val_loss: 8.6811e-06 - val_accuracy: 0.4972\n",
      "Epoch 17/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6845e-06 - accuracy: 0.5016 - val_loss: 8.6809e-06 - val_accuracy: 0.4972\n",
      "Epoch 18/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6897e-06 - accuracy: 0.5016 - val_loss: 8.8763e-06 - val_accuracy: 0.4972\n",
      "Epoch 19/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7358e-06 - accuracy: 0.5016 - val_loss: 8.7534e-06 - val_accuracy: 0.4972\n",
      "Epoch 20/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6999e-06 - accuracy: 0.5016 - val_loss: 8.7301e-06 - val_accuracy: 0.4972\n",
      "Epoch 21/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7007e-06 - accuracy: 0.5016 - val_loss: 9.1403e-06 - val_accuracy: 0.4972\n",
      "Epoch 22/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7051e-06 - accuracy: 0.5016 - val_loss: 8.7317e-06 - val_accuracy: 0.4972\n",
      "Epoch 23/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7270e-06 - accuracy: 0.5016 - val_loss: 8.7491e-06 - val_accuracy: 0.4972\n",
      "Epoch 24/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7073e-06 - accuracy: 0.5016 - val_loss: 8.7333e-06 - val_accuracy: 0.4972\n",
      "Epoch 25/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7478e-06 - accuracy: 0.5016 - val_loss: 9.2680e-06 - val_accuracy: 0.4972\n",
      "Epoch 26/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7394e-06 - accuracy: 0.5016 - val_loss: 8.6818e-06 - val_accuracy: 0.4972\n",
      "Epoch 27/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7135e-06 - accuracy: 0.5016 - val_loss: 8.7776e-06 - val_accuracy: 0.4972\n",
      "Epoch 28/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7331e-06 - accuracy: 0.5016 - val_loss: 8.7023e-06 - val_accuracy: 0.4972\n",
      "Epoch 29/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7080e-06 - accuracy: 0.5016 - val_loss: 8.6796e-06 - val_accuracy: 0.4972\n",
      "Epoch 30/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7403e-06 - accuracy: 0.5016 - val_loss: 8.7161e-06 - val_accuracy: 0.4972\n",
      "Epoch 31/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7038e-06 - accuracy: 0.5016 - val_loss: 8.7489e-06 - val_accuracy: 0.4972\n",
      "Epoch 32/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7348e-06 - accuracy: 0.5016 - val_loss: 8.8497e-06 - val_accuracy: 0.4972\n",
      "Epoch 33/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7010e-06 - accuracy: 0.5016 - val_loss: 8.6955e-06 - val_accuracy: 0.4972\n",
      "Epoch 34/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7322e-06 - accuracy: 0.5016 - val_loss: 8.6871e-06 - val_accuracy: 0.4972\n",
      "Epoch 35/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6963e-06 - accuracy: 0.5016 - val_loss: 8.7262e-06 - val_accuracy: 0.4972\n",
      "Epoch 36/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7194e-06 - accuracy: 0.5016 - val_loss: 8.7492e-06 - val_accuracy: 0.4972\n",
      "Epoch 37/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7026e-06 - accuracy: 0.5016 - val_loss: 8.8565e-06 - val_accuracy: 0.4972\n",
      "Epoch 38/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7271e-06 - accuracy: 0.5016 - val_loss: 8.7384e-06 - val_accuracy: 0.4972\n",
      "Epoch 39/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6939e-06 - accuracy: 0.5016 - val_loss: 8.7694e-06 - val_accuracy: 0.4972\n",
      "Epoch 40/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7434e-06 - accuracy: 0.5016 - val_loss: 9.0035e-06 - val_accuracy: 0.4972\n",
      "Epoch 41/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6851e-06 - accuracy: 0.5016 - val_loss: 8.8256e-06 - val_accuracy: 0.4972\n",
      "Epoch 42/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7216e-06 - accuracy: 0.5016 - val_loss: 8.7370e-06 - val_accuracy: 0.4972\n",
      "Epoch 43/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6809e-06 - accuracy: 0.5016 - val_loss: 8.7713e-06 - val_accuracy: 0.4972\n",
      "Epoch 44/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7064e-06 - accuracy: 0.5016 - val_loss: 9.1590e-06 - val_accuracy: 0.4972\n",
      "Epoch 45/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7073e-06 - accuracy: 0.5016 - val_loss: 8.7188e-06 - val_accuracy: 0.4972\n",
      "Epoch 46/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7093e-06 - accuracy: 0.5016 - val_loss: 8.6918e-06 - val_accuracy: 0.4972\n",
      "Epoch 47/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6823e-06 - accuracy: 0.5016 - val_loss: 8.7143e-06 - val_accuracy: 0.4972\n",
      "Epoch 48/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7031e-06 - accuracy: 0.5016 - val_loss: 8.6851e-06 - val_accuracy: 0.4972\n",
      "Epoch 49/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6910e-06 - accuracy: 0.5016 - val_loss: 8.6796e-06 - val_accuracy: 0.4972\n",
      "Epoch 50/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7238e-06 - accuracy: 0.5016 - val_loss: 8.7798e-06 - val_accuracy: 0.4972\n",
      "Epoch 51/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7162e-06 - accuracy: 0.5016 - val_loss: 8.7877e-06 - val_accuracy: 0.4972\n",
      "Epoch 52/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6828e-06 - accuracy: 0.5016 - val_loss: 9.0809e-06 - val_accuracy: 0.4972\n",
      "Epoch 53/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7502e-06 - accuracy: 0.5016 - val_loss: 9.0704e-06 - val_accuracy: 0.4972\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7239e-06 - accuracy: 0.5016 - val_loss: 9.7502e-06 - val_accuracy: 0.4972\n",
      "Epoch 55/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7105e-06 - accuracy: 0.5016 - val_loss: 8.7042e-06 - val_accuracy: 0.4972\n",
      "Epoch 56/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7545e-06 - accuracy: 0.5016 - val_loss: 8.8072e-06 - val_accuracy: 0.4972\n",
      "Epoch 57/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6947e-06 - accuracy: 0.5016 - val_loss: 8.6876e-06 - val_accuracy: 0.4972\n",
      "Epoch 58/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7019e-06 - accuracy: 0.5016 - val_loss: 8.7437e-06 - val_accuracy: 0.4972\n",
      "Epoch 59/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6912e-06 - accuracy: 0.5016 - val_loss: 8.7276e-06 - val_accuracy: 0.4972\n",
      "Epoch 60/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7256e-06 - accuracy: 0.5016 - val_loss: 8.6919e-06 - val_accuracy: 0.4972\n",
      "Epoch 61/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7131e-06 - accuracy: 0.5016 - val_loss: 8.7083e-06 - val_accuracy: 0.4972\n",
      "Epoch 62/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7202e-06 - accuracy: 0.5016 - val_loss: 8.6910e-06 - val_accuracy: 0.4972\n",
      "Epoch 63/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7332e-06 - accuracy: 0.5016 - val_loss: 8.7815e-06 - val_accuracy: 0.4972\n",
      "Epoch 64/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7314e-06 - accuracy: 0.5016 - val_loss: 8.8873e-06 - val_accuracy: 0.4972\n",
      "Epoch 65/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7078e-06 - accuracy: 0.5016 - val_loss: 9.2650e-06 - val_accuracy: 0.4972\n",
      "Epoch 66/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7172e-06 - accuracy: 0.5016 - val_loss: 8.7858e-06 - val_accuracy: 0.4972\n",
      "Epoch 67/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7073e-06 - accuracy: 0.5016 - val_loss: 8.7808e-06 - val_accuracy: 0.4972\n",
      "Epoch 68/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7381e-06 - accuracy: 0.5016 - val_loss: 8.9301e-06 - val_accuracy: 0.4972\n",
      "Epoch 69/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7389e-06 - accuracy: 0.5016 - val_loss: 8.8037e-06 - val_accuracy: 0.4972\n",
      "Epoch 70/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6946e-06 - accuracy: 0.5016 - val_loss: 8.6852e-06 - val_accuracy: 0.4972\n",
      "Epoch 71/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7088e-06 - accuracy: 0.5016 - val_loss: 8.6821e-06 - val_accuracy: 0.4972\n",
      "Epoch 72/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7045e-06 - accuracy: 0.5016 - val_loss: 8.7954e-06 - val_accuracy: 0.4972\n",
      "Epoch 73/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7145e-06 - accuracy: 0.5016 - val_loss: 8.6896e-06 - val_accuracy: 0.4972\n",
      "Epoch 74/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7411e-06 - accuracy: 0.5016 - val_loss: 8.7142e-06 - val_accuracy: 0.4972\n",
      "Epoch 75/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6577e-06 - accuracy: 0.5016 - val_loss: 8.6937e-06 - val_accuracy: 0.4972\n",
      "Epoch 76/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6971e-06 - accuracy: 0.5016 - val_loss: 8.6839e-06 - val_accuracy: 0.4972\n",
      "Epoch 77/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7052e-06 - accuracy: 0.5016 - val_loss: 8.7443e-06 - val_accuracy: 0.4972\n",
      "Epoch 78/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7437e-06 - accuracy: 0.5016 - val_loss: 8.7977e-06 - val_accuracy: 0.4972\n",
      "Epoch 79/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7287e-06 - accuracy: 0.5016 - val_loss: 8.6841e-06 - val_accuracy: 0.4972\n",
      "Epoch 80/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7033e-06 - accuracy: 0.5016 - val_loss: 8.8302e-06 - val_accuracy: 0.4972\n",
      "Epoch 81/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7575e-06 - accuracy: 0.5016 - val_loss: 8.6820e-06 - val_accuracy: 0.4972\n",
      "Epoch 82/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7054e-06 - accuracy: 0.5016 - val_loss: 8.7019e-06 - val_accuracy: 0.4972\n",
      "Epoch 83/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6894e-06 - accuracy: 0.5016 - val_loss: 8.8810e-06 - val_accuracy: 0.4972\n",
      "Epoch 84/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6879e-06 - accuracy: 0.5016 - val_loss: 8.8579e-06 - val_accuracy: 0.4972\n",
      "Epoch 85/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6774e-06 - accuracy: 0.5016 - val_loss: 8.8882e-06 - val_accuracy: 0.4972\n",
      "Epoch 86/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7414e-06 - accuracy: 0.5016 - val_loss: 8.9831e-06 - val_accuracy: 0.4972\n",
      "Epoch 87/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7105e-06 - accuracy: 0.5016 - val_loss: 8.7298e-06 - val_accuracy: 0.4972\n",
      "Epoch 88/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7460e-06 - accuracy: 0.5016 - val_loss: 8.6837e-06 - val_accuracy: 0.4972\n",
      "Epoch 89/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7298e-06 - accuracy: 0.5016 - val_loss: 9.0514e-06 - val_accuracy: 0.4972\n",
      "Epoch 90/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7083e-06 - accuracy: 0.5016 - val_loss: 8.7187e-06 - val_accuracy: 0.4972\n",
      "Epoch 91/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7398e-06 - accuracy: 0.5016 - val_loss: 8.7840e-06 - val_accuracy: 0.4972\n",
      "Epoch 92/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7045e-06 - accuracy: 0.5016 - val_loss: 8.7701e-06 - val_accuracy: 0.4972\n",
      "Epoch 93/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7453e-06 - accuracy: 0.5016 - val_loss: 8.6910e-06 - val_accuracy: 0.4972\n",
      "Epoch 94/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7440e-06 - accuracy: 0.5016 - val_loss: 8.6801e-06 - val_accuracy: 0.4972\n",
      "Epoch 95/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7070e-06 - accuracy: 0.5016 - val_loss: 8.8467e-06 - val_accuracy: 0.4972\n",
      "Epoch 96/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7381e-06 - accuracy: 0.5016 - val_loss: 8.6794e-06 - val_accuracy: 0.4972\n",
      "Epoch 97/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7072e-06 - accuracy: 0.5016 - val_loss: 9.0320e-06 - val_accuracy: 0.4972\n",
      "Epoch 98/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6983e-06 - accuracy: 0.5016 - val_loss: 8.8313e-06 - val_accuracy: 0.4972\n",
      "Epoch 99/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7162e-06 - accuracy: 0.5016 - val_loss: 9.1637e-06 - val_accuracy: 0.4972\n",
      "Epoch 100/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7287e-06 - accuracy: 0.5016 - val_loss: 9.0733e-06 - val_accuracy: 0.4972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/independent_batch64_e100_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/independent_batch64_e100_0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "801/801 [==============================] - 10s 13ms/step - loss: 1.0100e-05 - accuracy: 0.5007 - val_loss: 9.9920e-06 - val_accuracy: 0.4956\n",
      "Epoch 2/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0098e-05 - accuracy: 0.5007 - val_loss: 1.0182e-05 - val_accuracy: 0.4956\n",
      "Epoch 3/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0084e-05 - accuracy: 0.5007 - val_loss: 1.0582e-05 - val_accuracy: 0.4956\n",
      "Epoch 4/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0047e-05 - accuracy: 0.5007 - val_loss: 9.9736e-06 - val_accuracy: 0.4956\n",
      "Epoch 5/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0121e-05 - accuracy: 0.5007 - val_loss: 1.0098e-05 - val_accuracy: 0.4956\n",
      "Epoch 6/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0036e-05 - accuracy: 0.5007 - val_loss: 1.0053e-05 - val_accuracy: 0.4956\n",
      "Epoch 7/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0081e-05 - accuracy: 0.5007 - val_loss: 1.0082e-05 - val_accuracy: 0.4956\n",
      "Epoch 8/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0064e-05 - accuracy: 0.5007 - val_loss: 1.0050e-05 - val_accuracy: 0.4956\n",
      "Epoch 9/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0160e-05 - accuracy: 0.5007 - val_loss: 1.0008e-05 - val_accuracy: 0.4956\n",
      "Epoch 10/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0049e-05 - accuracy: 0.5007 - val_loss: 9.9910e-06 - val_accuracy: 0.4956\n",
      "Epoch 11/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0069e-05 - accuracy: 0.5007 - val_loss: 9.9726e-06 - val_accuracy: 0.4956\n",
      "Epoch 12/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0047e-05 - accuracy: 0.5007 - val_loss: 9.9804e-06 - val_accuracy: 0.4956\n",
      "Epoch 13/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0060e-05 - accuracy: 0.5007 - val_loss: 1.0267e-05 - val_accuracy: 0.4956\n",
      "Epoch 14/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0058e-05 - accuracy: 0.5007 - val_loss: 1.0126e-05 - val_accuracy: 0.4956\n",
      "Epoch 15/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0049e-05 - accuracy: 0.5007 - val_loss: 1.0637e-05 - val_accuracy: 0.4956\n",
      "Epoch 16/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0074e-05 - accuracy: 0.5007 - val_loss: 1.0105e-05 - val_accuracy: 0.4956\n",
      "Epoch 17/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0097e-05 - accuracy: 0.5007 - val_loss: 1.0433e-05 - val_accuracy: 0.4956\n",
      "Epoch 18/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0061e-05 - accuracy: 0.5007 - val_loss: 1.0157e-05 - val_accuracy: 0.4956\n",
      "Epoch 19/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0089e-05 - accuracy: 0.5007 - val_loss: 1.0018e-05 - val_accuracy: 0.4956\n",
      "Epoch 20/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0065e-05 - accuracy: 0.5007 - val_loss: 1.0065e-05 - val_accuracy: 0.4956\n",
      "Epoch 21/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0100e-05 - accuracy: 0.5007 - val_loss: 1.0161e-05 - val_accuracy: 0.4956\n",
      "Epoch 22/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0095e-05 - accuracy: 0.5007 - val_loss: 9.9762e-06 - val_accuracy: 0.4956\n",
      "Epoch 23/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0064e-05 - accuracy: 0.5007 - val_loss: 9.9719e-06 - val_accuracy: 0.4956\n",
      "Epoch 24/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0078e-05 - accuracy: 0.5007 - val_loss: 9.9778e-06 - val_accuracy: 0.4956\n",
      "Epoch 25/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0071e-05 - accuracy: 0.5007 - val_loss: 1.0327e-05 - val_accuracy: 0.4956\n",
      "Epoch 26/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0106e-05 - accuracy: 0.5007 - val_loss: 9.9825e-06 - val_accuracy: 0.4956\n",
      "Epoch 27/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0034e-05 - accuracy: 0.5007 - val_loss: 1.0092e-05 - val_accuracy: 0.4956\n",
      "Epoch 28/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0088e-05 - accuracy: 0.5007 - val_loss: 1.0380e-05 - val_accuracy: 0.4956\n",
      "Epoch 29/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0082e-05 - accuracy: 0.5007 - val_loss: 9.9839e-06 - val_accuracy: 0.4956\n",
      "Epoch 30/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0063e-05 - accuracy: 0.5007 - val_loss: 9.9867e-06 - val_accuracy: 0.4956\n",
      "Epoch 31/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0092e-05 - accuracy: 0.5007 - val_loss: 9.9949e-06 - val_accuracy: 0.4956\n",
      "Epoch 32/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0061e-05 - accuracy: 0.5007 - val_loss: 9.9938e-06 - val_accuracy: 0.4956\n",
      "Epoch 33/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0075e-05 - accuracy: 0.5007 - val_loss: 1.0145e-05 - val_accuracy: 0.4956\n",
      "Epoch 34/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0102e-05 - accuracy: 0.5007 - val_loss: 1.1089e-05 - val_accuracy: 0.4956\n",
      "Epoch 35/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0053e-05 - accuracy: 0.5007 - val_loss: 9.9725e-06 - val_accuracy: 0.4956\n",
      "Epoch 36/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0053e-05 - accuracy: 0.5007 - val_loss: 1.0109e-05 - val_accuracy: 0.4956\n",
      "Epoch 37/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0091e-05 - accuracy: 0.5007 - val_loss: 1.0274e-05 - val_accuracy: 0.4956\n",
      "Epoch 38/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0046e-05 - accuracy: 0.5007 - val_loss: 1.0097e-05 - val_accuracy: 0.4956\n",
      "Epoch 39/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0065e-05 - accuracy: 0.5007 - val_loss: 1.0063e-05 - val_accuracy: 0.4956\n",
      "Epoch 40/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0075e-05 - accuracy: 0.5007 - val_loss: 1.0300e-05 - val_accuracy: 0.4956\n",
      "Epoch 41/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0107e-05 - accuracy: 0.5007 - val_loss: 1.0032e-05 - val_accuracy: 0.4956\n",
      "Epoch 42/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0099e-05 - accuracy: 0.5007 - val_loss: 1.0015e-05 - val_accuracy: 0.4956\n",
      "Epoch 43/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0071e-05 - accuracy: 0.5007 - val_loss: 1.0313e-05 - val_accuracy: 0.4956\n",
      "Epoch 44/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0142e-05 - accuracy: 0.5007 - val_loss: 1.0468e-05 - val_accuracy: 0.4956\n",
      "Epoch 45/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0064e-05 - accuracy: 0.5007 - val_loss: 9.9923e-06 - val_accuracy: 0.4956\n",
      "Epoch 46/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0109e-05 - accuracy: 0.5007 - val_loss: 9.9811e-06 - val_accuracy: 0.4956\n",
      "Epoch 47/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0070e-05 - accuracy: 0.5007 - val_loss: 1.0097e-05 - val_accuracy: 0.4956\n",
      "Epoch 48/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0065e-05 - accuracy: 0.5007 - val_loss: 1.0166e-05 - val_accuracy: 0.4956\n",
      "Epoch 49/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0082e-05 - accuracy: 0.5007 - val_loss: 1.0184e-05 - val_accuracy: 0.4956\n",
      "Epoch 50/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0054e-05 - accuracy: 0.5007 - val_loss: 1.0225e-05 - val_accuracy: 0.4956\n",
      "Epoch 51/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0033e-05 - accuracy: 0.5007 - val_loss: 1.0178e-05 - val_accuracy: 0.4956\n",
      "Epoch 52/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0112e-05 - accuracy: 0.5007 - val_loss: 1.0476e-05 - val_accuracy: 0.4956\n",
      "Epoch 53/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0069e-05 - accuracy: 0.5007 - val_loss: 1.0075e-05 - val_accuracy: 0.4956\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0067e-05 - accuracy: 0.5007 - val_loss: 1.0037e-05 - val_accuracy: 0.4956\n",
      "Epoch 55/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0056e-05 - accuracy: 0.5007 - val_loss: 1.0046e-05 - val_accuracy: 0.4956\n",
      "Epoch 56/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0049e-05 - accuracy: 0.5007 - val_loss: 1.0013e-05 - val_accuracy: 0.4956\n",
      "Epoch 57/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0079e-05 - accuracy: 0.5007 - val_loss: 1.0275e-05 - val_accuracy: 0.4956\n",
      "Epoch 58/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0072e-05 - accuracy: 0.5007 - val_loss: 1.0088e-05 - val_accuracy: 0.4956\n",
      "Epoch 59/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0112e-05 - accuracy: 0.5007 - val_loss: 1.0075e-05 - val_accuracy: 0.4956\n",
      "Epoch 60/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0067e-05 - accuracy: 0.5007 - val_loss: 1.0246e-05 - val_accuracy: 0.4956\n",
      "Epoch 61/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0061e-05 - accuracy: 0.5007 - val_loss: 1.0181e-05 - val_accuracy: 0.4956\n",
      "Epoch 62/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0068e-05 - accuracy: 0.5007 - val_loss: 9.9849e-06 - val_accuracy: 0.4956\n",
      "Epoch 63/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0065e-05 - accuracy: 0.5007 - val_loss: 1.0021e-05 - val_accuracy: 0.4956\n",
      "Epoch 64/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0074e-05 - accuracy: 0.5007 - val_loss: 1.0028e-05 - val_accuracy: 0.4956\n",
      "Epoch 65/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0082e-05 - accuracy: 0.5007 - val_loss: 1.0128e-05 - val_accuracy: 0.4956\n",
      "Epoch 66/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0148e-05 - accuracy: 0.5007 - val_loss: 9.9936e-06 - val_accuracy: 0.4956\n",
      "Epoch 67/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0039e-05 - accuracy: 0.5007 - val_loss: 9.9719e-06 - val_accuracy: 0.4956\n",
      "Epoch 68/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0059e-05 - accuracy: 0.5007 - val_loss: 9.9719e-06 - val_accuracy: 0.4956\n",
      "Epoch 69/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0057e-05 - accuracy: 0.5007 - val_loss: 9.9909e-06 - val_accuracy: 0.4956\n",
      "Epoch 70/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0064e-05 - accuracy: 0.5007 - val_loss: 9.9733e-06 - val_accuracy: 0.4956\n",
      "Epoch 71/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0045e-05 - accuracy: 0.5007 - val_loss: 9.9944e-06 - val_accuracy: 0.4956\n",
      "Epoch 72/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0089e-05 - accuracy: 0.5007 - val_loss: 9.9758e-06 - val_accuracy: 0.4956\n",
      "Epoch 73/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0051e-05 - accuracy: 0.5007 - val_loss: 1.0047e-05 - val_accuracy: 0.4956\n",
      "Epoch 74/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0098e-05 - accuracy: 0.5007 - val_loss: 9.9905e-06 - val_accuracy: 0.4956\n",
      "Epoch 75/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0068e-05 - accuracy: 0.5007 - val_loss: 9.9731e-06 - val_accuracy: 0.4956\n",
      "Epoch 76/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0075e-05 - accuracy: 0.5007 - val_loss: 1.0235e-05 - val_accuracy: 0.4956\n",
      "Epoch 77/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0040e-05 - accuracy: 0.5007 - val_loss: 9.9739e-06 - val_accuracy: 0.4956\n",
      "Epoch 78/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0049e-05 - accuracy: 0.5007 - val_loss: 1.0214e-05 - val_accuracy: 0.4956\n",
      "Epoch 79/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0073e-05 - accuracy: 0.5007 - val_loss: 1.0219e-05 - val_accuracy: 0.4956\n",
      "Epoch 80/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0051e-05 - accuracy: 0.5007 - val_loss: 9.9725e-06 - val_accuracy: 0.4956\n",
      "Epoch 81/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0116e-05 - accuracy: 0.5007 - val_loss: 1.0246e-05 - val_accuracy: 0.4956\n",
      "Epoch 82/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0065e-05 - accuracy: 0.5007 - val_loss: 1.0000e-05 - val_accuracy: 0.4956\n",
      "Epoch 83/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0061e-05 - accuracy: 0.5007 - val_loss: 9.9725e-06 - val_accuracy: 0.4956\n",
      "Epoch 84/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0074e-05 - accuracy: 0.5007 - val_loss: 9.9730e-06 - val_accuracy: 0.4956\n",
      "Epoch 85/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0096e-05 - accuracy: 0.5007 - val_loss: 1.0447e-05 - val_accuracy: 0.4956\n",
      "Epoch 86/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0055e-05 - accuracy: 0.5007 - val_loss: 1.0685e-05 - val_accuracy: 0.4956\n",
      "Epoch 87/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0063e-05 - accuracy: 0.5007 - val_loss: 9.9815e-06 - val_accuracy: 0.4956\n",
      "Epoch 88/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0075e-05 - accuracy: 0.5007 - val_loss: 9.9755e-06 - val_accuracy: 0.4956\n",
      "Epoch 89/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0075e-05 - accuracy: 0.5007 - val_loss: 1.0252e-05 - val_accuracy: 0.4956\n",
      "Epoch 90/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0092e-05 - accuracy: 0.5007 - val_loss: 9.9819e-06 - val_accuracy: 0.4956\n",
      "Epoch 91/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0067e-05 - accuracy: 0.5007 - val_loss: 1.0173e-05 - val_accuracy: 0.4956\n",
      "Epoch 92/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0086e-05 - accuracy: 0.5007 - val_loss: 1.0216e-05 - val_accuracy: 0.4956\n",
      "Epoch 93/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0107e-05 - accuracy: 0.5007 - val_loss: 9.9885e-06 - val_accuracy: 0.4956\n",
      "Epoch 94/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0057e-05 - accuracy: 0.5007 - val_loss: 1.0009e-05 - val_accuracy: 0.4956\n",
      "Epoch 95/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0025e-05 - accuracy: 0.5007 - val_loss: 1.0503e-05 - val_accuracy: 0.4956\n",
      "Epoch 96/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0093e-05 - accuracy: 0.5007 - val_loss: 1.0499e-05 - val_accuracy: 0.4956\n",
      "Epoch 97/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0047e-05 - accuracy: 0.5007 - val_loss: 9.9735e-06 - val_accuracy: 0.4956\n",
      "Epoch 98/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0084e-05 - accuracy: 0.5007 - val_loss: 9.9721e-06 - val_accuracy: 0.4956\n",
      "Epoch 99/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0068e-05 - accuracy: 0.5007 - val_loss: 9.9736e-06 - val_accuracy: 0.4956\n",
      "Epoch 100/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 1.0110e-05 - accuracy: 0.5007 - val_loss: 1.0009e-05 - val_accuracy: 0.4956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/independent_batch64_e100_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/independent_batch64_e100_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7320e-06 - accuracy: 0.5000 - val_loss: 8.5085e-06 - val_accuracy: 0.4981\n",
      "Epoch 2/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7076e-06 - accuracy: 0.5000 - val_loss: 8.4971e-06 - val_accuracy: 0.4981\n",
      "Epoch 3/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7066e-06 - accuracy: 0.5000 - val_loss: 8.8625e-06 - val_accuracy: 0.4981\n",
      "Epoch 4/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7036e-06 - accuracy: 0.5000 - val_loss: 8.5875e-06 - val_accuracy: 0.4981\n",
      "Epoch 5/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7255e-06 - accuracy: 0.5000 - val_loss: 8.6033e-06 - val_accuracy: 0.4981\n",
      "Epoch 6/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7335e-06 - accuracy: 0.5000 - val_loss: 8.5816e-06 - val_accuracy: 0.4981\n",
      "Epoch 7/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7261e-06 - accuracy: 0.5000 - val_loss: 8.7585e-06 - val_accuracy: 0.4981\n",
      "Epoch 8/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7448e-06 - accuracy: 0.5000 - val_loss: 8.5229e-06 - val_accuracy: 0.4981\n",
      "Epoch 9/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7198e-06 - accuracy: 0.5000 - val_loss: 8.4984e-06 - val_accuracy: 0.4981\n",
      "Epoch 10/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7166e-06 - accuracy: 0.5000 - val_loss: 8.5046e-06 - val_accuracy: 0.4981\n",
      "Epoch 11/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7010e-06 - accuracy: 0.5000 - val_loss: 8.5480e-06 - val_accuracy: 0.4981\n",
      "Epoch 12/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7377e-06 - accuracy: 0.5000 - val_loss: 9.0877e-06 - val_accuracy: 0.4981\n",
      "Epoch 13/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7041e-06 - accuracy: 0.5000 - val_loss: 8.6070e-06 - val_accuracy: 0.4981\n",
      "Epoch 14/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7076e-06 - accuracy: 0.5000 - val_loss: 8.6281e-06 - val_accuracy: 0.4981\n",
      "Epoch 15/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7256e-06 - accuracy: 0.5000 - val_loss: 8.4974e-06 - val_accuracy: 0.4981\n",
      "Epoch 16/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7163e-06 - accuracy: 0.5000 - val_loss: 8.4988e-06 - val_accuracy: 0.4981\n",
      "Epoch 17/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7094e-06 - accuracy: 0.5000 - val_loss: 8.6639e-06 - val_accuracy: 0.4981\n",
      "Epoch 18/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7592e-06 - accuracy: 0.5000 - val_loss: 8.7505e-06 - val_accuracy: 0.4981\n",
      "Epoch 19/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7367e-06 - accuracy: 0.5000 - val_loss: 8.7541e-06 - val_accuracy: 0.4981\n",
      "Epoch 20/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6830e-06 - accuracy: 0.5000 - val_loss: 8.6708e-06 - val_accuracy: 0.4981\n",
      "Epoch 21/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7132e-06 - accuracy: 0.5000 - val_loss: 9.1580e-06 - val_accuracy: 0.4981\n",
      "Epoch 22/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7098e-06 - accuracy: 0.5000 - val_loss: 8.5456e-06 - val_accuracy: 0.4981\n",
      "Epoch 23/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7128e-06 - accuracy: 0.5000 - val_loss: 8.5500e-06 - val_accuracy: 0.4981\n",
      "Epoch 24/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7127e-06 - accuracy: 0.5000 - val_loss: 8.6655e-06 - val_accuracy: 0.4981\n",
      "Epoch 25/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7235e-06 - accuracy: 0.5000 - val_loss: 8.6119e-06 - val_accuracy: 0.4981\n",
      "Epoch 26/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6987e-06 - accuracy: 0.5000 - val_loss: 8.7084e-06 - val_accuracy: 0.4981\n",
      "Epoch 27/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6953e-06 - accuracy: 0.5000 - val_loss: 8.6285e-06 - val_accuracy: 0.4981\n",
      "Epoch 28/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7011e-06 - accuracy: 0.5000 - val_loss: 8.4972e-06 - val_accuracy: 0.4981\n",
      "Epoch 29/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7290e-06 - accuracy: 0.5000 - val_loss: 8.5026e-06 - val_accuracy: 0.4981\n",
      "Epoch 30/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6999e-06 - accuracy: 0.5000 - val_loss: 8.5013e-06 - val_accuracy: 0.4981\n",
      "Epoch 31/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6929e-06 - accuracy: 0.5000 - val_loss: 8.5549e-06 - val_accuracy: 0.4981\n",
      "Epoch 32/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7155e-06 - accuracy: 0.5000 - val_loss: 8.4974e-06 - val_accuracy: 0.4981\n",
      "Epoch 33/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7178e-06 - accuracy: 0.5000 - val_loss: 8.7228e-06 - val_accuracy: 0.4981\n",
      "Epoch 34/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6949e-06 - accuracy: 0.5000 - val_loss: 9.1570e-06 - val_accuracy: 0.4981\n",
      "Epoch 35/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7281e-06 - accuracy: 0.5000 - val_loss: 8.5237e-06 - val_accuracy: 0.4981\n",
      "Epoch 36/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7456e-06 - accuracy: 0.5000 - val_loss: 8.5059e-06 - val_accuracy: 0.4981\n",
      "Epoch 37/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7444e-06 - accuracy: 0.5000 - val_loss: 8.6066e-06 - val_accuracy: 0.4981\n",
      "Epoch 38/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7710e-06 - accuracy: 0.5000 - val_loss: 8.4984e-06 - val_accuracy: 0.4981\n",
      "Epoch 39/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6901e-06 - accuracy: 0.5000 - val_loss: 8.5303e-06 - val_accuracy: 0.4981\n",
      "Epoch 40/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7562e-06 - accuracy: 0.5000 - val_loss: 8.5983e-06 - val_accuracy: 0.4981\n",
      "Epoch 41/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7172e-06 - accuracy: 0.5000 - val_loss: 8.5378e-06 - val_accuracy: 0.4981\n",
      "Epoch 42/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7028e-06 - accuracy: 0.5000 - val_loss: 8.5085e-06 - val_accuracy: 0.4981\n",
      "Epoch 43/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7126e-06 - accuracy: 0.5000 - val_loss: 8.5884e-06 - val_accuracy: 0.4981\n",
      "Epoch 44/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6866e-06 - accuracy: 0.5000 - val_loss: 8.4973e-06 - val_accuracy: 0.4981\n",
      "Epoch 45/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7159e-06 - accuracy: 0.5000 - val_loss: 8.5385e-06 - val_accuracy: 0.4981\n",
      "Epoch 46/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7054e-06 - accuracy: 0.5000 - val_loss: 8.5821e-06 - val_accuracy: 0.4981\n",
      "Epoch 47/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7056e-06 - accuracy: 0.5000 - val_loss: 8.4976e-06 - val_accuracy: 0.4981\n",
      "Epoch 48/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7412e-06 - accuracy: 0.5000 - val_loss: 8.4990e-06 - val_accuracy: 0.4981\n",
      "Epoch 49/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7304e-06 - accuracy: 0.5000 - val_loss: 8.5082e-06 - val_accuracy: 0.4981\n",
      "Epoch 50/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7144e-06 - accuracy: 0.5000 - val_loss: 8.7085e-06 - val_accuracy: 0.4981\n",
      "Epoch 51/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7087e-06 - accuracy: 0.5000 - val_loss: 8.5088e-06 - val_accuracy: 0.4981\n",
      "Epoch 52/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6859e-06 - accuracy: 0.5000 - val_loss: 8.5201e-06 - val_accuracy: 0.4981\n",
      "Epoch 53/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7386e-06 - accuracy: 0.5000 - val_loss: 9.5010e-06 - val_accuracy: 0.4981\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7101e-06 - accuracy: 0.5000 - val_loss: 8.6527e-06 - val_accuracy: 0.4981\n",
      "Epoch 55/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7024e-06 - accuracy: 0.5000 - val_loss: 8.5015e-06 - val_accuracy: 0.4981\n",
      "Epoch 56/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7311e-06 - accuracy: 0.5000 - val_loss: 8.6123e-06 - val_accuracy: 0.4981\n",
      "Epoch 57/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6940e-06 - accuracy: 0.5000 - val_loss: 8.6891e-06 - val_accuracy: 0.4981\n",
      "Epoch 58/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6953e-06 - accuracy: 0.5000 - val_loss: 8.8769e-06 - val_accuracy: 0.4981\n",
      "Epoch 59/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7026e-06 - accuracy: 0.5000 - val_loss: 8.4986e-06 - val_accuracy: 0.4981\n",
      "Epoch 60/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6866e-06 - accuracy: 0.5000 - val_loss: 8.4971e-06 - val_accuracy: 0.4981\n",
      "Epoch 61/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7029e-06 - accuracy: 0.5000 - val_loss: 8.4998e-06 - val_accuracy: 0.4981\n",
      "Epoch 62/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7455e-06 - accuracy: 0.5000 - val_loss: 8.4972e-06 - val_accuracy: 0.4981\n",
      "Epoch 63/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7107e-06 - accuracy: 0.5000 - val_loss: 8.6205e-06 - val_accuracy: 0.4981\n",
      "Epoch 64/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7214e-06 - accuracy: 0.5000 - val_loss: 8.5147e-06 - val_accuracy: 0.4981\n",
      "Epoch 65/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7264e-06 - accuracy: 0.5000 - val_loss: 8.4980e-06 - val_accuracy: 0.4981\n",
      "Epoch 66/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7014e-06 - accuracy: 0.5000 - val_loss: 8.5603e-06 - val_accuracy: 0.4981\n",
      "Epoch 67/100\n",
      "801/801 [==============================] - 10s 13ms/step - loss: 8.7385e-06 - accuracy: 0.5000 - val_loss: 8.4971e-06 - val_accuracy: 0.4981\n",
      "Epoch 68/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7009e-06 - accuracy: 0.5000 - val_loss: 8.7992e-06 - val_accuracy: 0.4981\n",
      "Epoch 69/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7403e-06 - accuracy: 0.5000 - val_loss: 8.5731e-06 - val_accuracy: 0.4981\n",
      "Epoch 70/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7195e-06 - accuracy: 0.5000 - val_loss: 9.1346e-06 - val_accuracy: 0.4981\n",
      "Epoch 71/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7264e-06 - accuracy: 0.5000 - val_loss: 8.8525e-06 - val_accuracy: 0.4981\n",
      "Epoch 72/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7009e-06 - accuracy: 0.5000 - val_loss: 8.6346e-06 - val_accuracy: 0.4981\n",
      "Epoch 73/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7081e-06 - accuracy: 0.5000 - val_loss: 8.5602e-06 - val_accuracy: 0.4981\n",
      "Epoch 74/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6979e-06 - accuracy: 0.5000 - val_loss: 8.5030e-06 - val_accuracy: 0.4981\n",
      "Epoch 75/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6871e-06 - accuracy: 0.5000 - val_loss: 8.5183e-06 - val_accuracy: 0.4981\n",
      "Epoch 76/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7225e-06 - accuracy: 0.5000 - val_loss: 8.7293e-06 - val_accuracy: 0.4981\n",
      "Epoch 77/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7019e-06 - accuracy: 0.5000 - val_loss: 8.8009e-06 - val_accuracy: 0.4981\n",
      "Epoch 78/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7268e-06 - accuracy: 0.5000 - val_loss: 8.6465e-06 - val_accuracy: 0.4981\n",
      "Epoch 79/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6913e-06 - accuracy: 0.5000 - val_loss: 8.5011e-06 - val_accuracy: 0.4981\n",
      "Epoch 80/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7036e-06 - accuracy: 0.5000 - val_loss: 8.5183e-06 - val_accuracy: 0.4981\n",
      "Epoch 81/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7428e-06 - accuracy: 0.5000 - val_loss: 8.5875e-06 - val_accuracy: 0.4981\n",
      "Epoch 82/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7259e-06 - accuracy: 0.5000 - val_loss: 8.4974e-06 - val_accuracy: 0.4981\n",
      "Epoch 83/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7037e-06 - accuracy: 0.5000 - val_loss: 8.5106e-06 - val_accuracy: 0.4981\n",
      "Epoch 84/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7111e-06 - accuracy: 0.5000 - val_loss: 8.4997e-06 - val_accuracy: 0.4981\n",
      "Epoch 85/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7170e-06 - accuracy: 0.5000 - val_loss: 8.5430e-06 - val_accuracy: 0.4981\n",
      "Epoch 86/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6854e-06 - accuracy: 0.5000 - val_loss: 8.5170e-06 - val_accuracy: 0.4981\n",
      "Epoch 87/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7298e-06 - accuracy: 0.5000 - val_loss: 9.0722e-06 - val_accuracy: 0.4981\n",
      "Epoch 88/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7231e-06 - accuracy: 0.5000 - val_loss: 8.5168e-06 - val_accuracy: 0.4981\n",
      "Epoch 89/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7057e-06 - accuracy: 0.5000 - val_loss: 8.5219e-06 - val_accuracy: 0.4981\n",
      "Epoch 90/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7094e-06 - accuracy: 0.5000 - val_loss: 8.7726e-06 - val_accuracy: 0.4981\n",
      "Epoch 91/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7408e-06 - accuracy: 0.5000 - val_loss: 8.6522e-06 - val_accuracy: 0.4981\n",
      "Epoch 92/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7015e-06 - accuracy: 0.5000 - val_loss: 8.6010e-06 - val_accuracy: 0.4981\n",
      "Epoch 93/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7332e-06 - accuracy: 0.5000 - val_loss: 8.6056e-06 - val_accuracy: 0.4981\n",
      "Epoch 94/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7055e-06 - accuracy: 0.5000 - val_loss: 8.9796e-06 - val_accuracy: 0.4981\n",
      "Epoch 95/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7205e-06 - accuracy: 0.5000 - val_loss: 8.5315e-06 - val_accuracy: 0.4981\n",
      "Epoch 96/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7331e-06 - accuracy: 0.5000 - val_loss: 8.6673e-06 - val_accuracy: 0.4981\n",
      "Epoch 97/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7150e-06 - accuracy: 0.5000 - val_loss: 8.5039e-06 - val_accuracy: 0.4981\n",
      "Epoch 98/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7141e-06 - accuracy: 0.5000 - val_loss: 8.6360e-06 - val_accuracy: 0.4981\n",
      "Epoch 99/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.7023e-06 - accuracy: 0.5000 - val_loss: 8.4984e-06 - val_accuracy: 0.4981\n",
      "Epoch 100/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.6900e-06 - accuracy: 0.5000 - val_loss: 8.6028e-06 - val_accuracy: 0.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/independent_batch64_e100_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/independent_batch64_e100_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9348e-06 - accuracy: 0.4968 - val_loss: 8.1613e-06 - val_accuracy: 0.4865\n",
      "Epoch 2/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9523e-06 - accuracy: 0.4968 - val_loss: 7.9740e-06 - val_accuracy: 0.4865\n",
      "Epoch 3/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9542e-06 - accuracy: 0.4968 - val_loss: 8.0230e-06 - val_accuracy: 0.4865\n",
      "Epoch 4/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9523e-06 - accuracy: 0.4968 - val_loss: 8.1394e-06 - val_accuracy: 0.4865\n",
      "Epoch 5/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9611e-06 - accuracy: 0.4968 - val_loss: 8.0440e-06 - val_accuracy: 0.4865\n",
      "Epoch 6/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9256e-06 - accuracy: 0.4968 - val_loss: 8.0962e-06 - val_accuracy: 0.4865\n",
      "Epoch 7/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9253e-06 - accuracy: 0.4968 - val_loss: 7.9715e-06 - val_accuracy: 0.4865\n",
      "Epoch 8/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9374e-06 - accuracy: 0.4968 - val_loss: 8.1652e-06 - val_accuracy: 0.4865\n",
      "Epoch 9/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9708e-06 - accuracy: 0.4968 - val_loss: 8.0966e-06 - val_accuracy: 0.4865\n",
      "Epoch 10/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9325e-06 - accuracy: 0.4968 - val_loss: 7.9516e-06 - val_accuracy: 0.4865\n",
      "Epoch 11/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9587e-06 - accuracy: 0.4968 - val_loss: 8.5961e-06 - val_accuracy: 0.4865\n",
      "Epoch 12/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9408e-06 - accuracy: 0.4968 - val_loss: 7.9586e-06 - val_accuracy: 0.4865\n",
      "Epoch 13/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9616e-06 - accuracy: 0.4968 - val_loss: 7.9796e-06 - val_accuracy: 0.4865\n",
      "Epoch 14/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9168e-06 - accuracy: 0.4968 - val_loss: 8.0096e-06 - val_accuracy: 0.4865\n",
      "Epoch 15/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9236e-06 - accuracy: 0.4968 - val_loss: 7.9535e-06 - val_accuracy: 0.4865\n",
      "Epoch 16/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9418e-06 - accuracy: 0.4968 - val_loss: 7.9517e-06 - val_accuracy: 0.4865\n",
      "Epoch 17/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9416e-06 - accuracy: 0.4968 - val_loss: 7.9705e-06 - val_accuracy: 0.4865\n",
      "Epoch 18/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9335e-06 - accuracy: 0.4968 - val_loss: 8.0075e-06 - val_accuracy: 0.4865\n",
      "Epoch 19/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9340e-06 - accuracy: 0.4968 - val_loss: 8.1113e-06 - val_accuracy: 0.4865\n",
      "Epoch 20/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9421e-06 - accuracy: 0.4968 - val_loss: 8.1929e-06 - val_accuracy: 0.4865\n",
      "Epoch 21/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9834e-06 - accuracy: 0.4968 - val_loss: 8.0364e-06 - val_accuracy: 0.4865\n",
      "Epoch 22/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9319e-06 - accuracy: 0.4968 - val_loss: 7.9975e-06 - val_accuracy: 0.4865\n",
      "Epoch 23/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9358e-06 - accuracy: 0.4968 - val_loss: 7.9787e-06 - val_accuracy: 0.4865\n",
      "Epoch 24/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9482e-06 - accuracy: 0.4968 - val_loss: 8.2956e-06 - val_accuracy: 0.4865\n",
      "Epoch 25/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9477e-06 - accuracy: 0.4968 - val_loss: 8.4865e-06 - val_accuracy: 0.4865\n",
      "Epoch 26/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9384e-06 - accuracy: 0.4968 - val_loss: 8.4934e-06 - val_accuracy: 0.4865\n",
      "Epoch 27/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9677e-06 - accuracy: 0.4968 - val_loss: 7.9516e-06 - val_accuracy: 0.4865\n",
      "Epoch 28/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9044e-06 - accuracy: 0.4968 - val_loss: 7.9746e-06 - val_accuracy: 0.4865\n",
      "Epoch 29/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9105e-06 - accuracy: 0.4968 - val_loss: 7.9707e-06 - val_accuracy: 0.4865\n",
      "Epoch 30/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9473e-06 - accuracy: 0.4968 - val_loss: 8.1525e-06 - val_accuracy: 0.4865\n",
      "Epoch 31/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9706e-06 - accuracy: 0.4968 - val_loss: 7.9513e-06 - val_accuracy: 0.4865\n",
      "Epoch 32/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9301e-06 - accuracy: 0.4968 - val_loss: 7.9516e-06 - val_accuracy: 0.4865\n",
      "Epoch 33/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9241e-06 - accuracy: 0.4968 - val_loss: 8.0511e-06 - val_accuracy: 0.4865\n",
      "Epoch 34/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9401e-06 - accuracy: 0.4968 - val_loss: 8.0319e-06 - val_accuracy: 0.4865\n",
      "Epoch 35/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9354e-06 - accuracy: 0.4968 - val_loss: 7.9549e-06 - val_accuracy: 0.4865\n",
      "Epoch 36/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9439e-06 - accuracy: 0.4968 - val_loss: 8.0828e-06 - val_accuracy: 0.4865\n",
      "Epoch 37/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9372e-06 - accuracy: 0.4968 - val_loss: 7.9686e-06 - val_accuracy: 0.4865\n",
      "Epoch 38/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9718e-06 - accuracy: 0.4968 - val_loss: 7.9514e-06 - val_accuracy: 0.4865\n",
      "Epoch 39/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9424e-06 - accuracy: 0.4968 - val_loss: 8.2655e-06 - val_accuracy: 0.4865\n",
      "Epoch 40/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9403e-06 - accuracy: 0.4968 - val_loss: 8.0481e-06 - val_accuracy: 0.4865\n",
      "Epoch 41/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9227e-06 - accuracy: 0.4968 - val_loss: 8.1720e-06 - val_accuracy: 0.4865\n",
      "Epoch 42/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9397e-06 - accuracy: 0.4968 - val_loss: 8.0005e-06 - val_accuracy: 0.4865\n",
      "Epoch 43/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9345e-06 - accuracy: 0.4968 - val_loss: 8.0083e-06 - val_accuracy: 0.4865\n",
      "Epoch 44/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9641e-06 - accuracy: 0.4968 - val_loss: 7.9564e-06 - val_accuracy: 0.4865\n",
      "Epoch 45/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9676e-06 - accuracy: 0.4968 - val_loss: 7.9515e-06 - val_accuracy: 0.4865\n",
      "Epoch 46/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9206e-06 - accuracy: 0.4968 - val_loss: 7.9513e-06 - val_accuracy: 0.4865\n",
      "Epoch 47/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9526e-06 - accuracy: 0.4968 - val_loss: 7.9515e-06 - val_accuracy: 0.4865\n",
      "Epoch 48/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9553e-06 - accuracy: 0.4968 - val_loss: 8.1962e-06 - val_accuracy: 0.4865\n",
      "Epoch 49/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9272e-06 - accuracy: 0.4968 - val_loss: 8.0402e-06 - val_accuracy: 0.4865\n",
      "Epoch 50/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9456e-06 - accuracy: 0.4968 - val_loss: 8.0411e-06 - val_accuracy: 0.4865\n",
      "Epoch 51/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9277e-06 - accuracy: 0.4968 - val_loss: 8.1399e-06 - val_accuracy: 0.4865\n",
      "Epoch 52/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9300e-06 - accuracy: 0.4968 - val_loss: 7.9514e-06 - val_accuracy: 0.4865\n",
      "Epoch 53/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9221e-06 - accuracy: 0.4968 - val_loss: 7.9522e-06 - val_accuracy: 0.4865\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9607e-06 - accuracy: 0.4968 - val_loss: 7.9910e-06 - val_accuracy: 0.4865\n",
      "Epoch 55/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9307e-06 - accuracy: 0.4968 - val_loss: 7.9802e-06 - val_accuracy: 0.4865\n",
      "Epoch 56/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9657e-06 - accuracy: 0.4968 - val_loss: 8.0616e-06 - val_accuracy: 0.4865\n",
      "Epoch 57/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9229e-06 - accuracy: 0.4968 - val_loss: 7.9674e-06 - val_accuracy: 0.4865\n",
      "Epoch 58/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9451e-06 - accuracy: 0.4968 - val_loss: 8.0822e-06 - val_accuracy: 0.4865\n",
      "Epoch 59/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9456e-06 - accuracy: 0.4968 - val_loss: 8.0814e-06 - val_accuracy: 0.4865\n",
      "Epoch 60/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9370e-06 - accuracy: 0.4968 - val_loss: 8.0639e-06 - val_accuracy: 0.4865\n",
      "Epoch 61/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9442e-06 - accuracy: 0.4968 - val_loss: 8.1685e-06 - val_accuracy: 0.4865\n",
      "Epoch 62/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9346e-06 - accuracy: 0.4968 - val_loss: 8.0953e-06 - val_accuracy: 0.4865\n",
      "Epoch 63/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9116e-06 - accuracy: 0.4968 - val_loss: 7.9518e-06 - val_accuracy: 0.4865\n",
      "Epoch 64/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9515e-06 - accuracy: 0.4968 - val_loss: 8.0877e-06 - val_accuracy: 0.4865\n",
      "Epoch 65/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9895e-06 - accuracy: 0.4968 - val_loss: 8.2594e-06 - val_accuracy: 0.4865\n",
      "Epoch 66/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9589e-06 - accuracy: 0.4968 - val_loss: 7.9729e-06 - val_accuracy: 0.4865\n",
      "Epoch 67/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9652e-06 - accuracy: 0.4968 - val_loss: 8.1698e-06 - val_accuracy: 0.4865\n",
      "Epoch 68/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9410e-06 - accuracy: 0.4968 - val_loss: 7.9854e-06 - val_accuracy: 0.4865\n",
      "Epoch 69/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9149e-06 - accuracy: 0.4968 - val_loss: 7.9513e-06 - val_accuracy: 0.4865\n",
      "Epoch 70/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9793e-06 - accuracy: 0.4968 - val_loss: 7.9527e-06 - val_accuracy: 0.4865\n",
      "Epoch 71/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9510e-06 - accuracy: 0.4968 - val_loss: 8.1596e-06 - val_accuracy: 0.4865\n",
      "Epoch 72/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9142e-06 - accuracy: 0.4968 - val_loss: 7.9559e-06 - val_accuracy: 0.4865\n",
      "Epoch 73/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9245e-06 - accuracy: 0.4968 - val_loss: 7.9705e-06 - val_accuracy: 0.4865\n",
      "Epoch 74/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9639e-06 - accuracy: 0.4968 - val_loss: 8.1629e-06 - val_accuracy: 0.4865\n",
      "Epoch 75/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9995e-06 - accuracy: 0.4968 - val_loss: 7.9612e-06 - val_accuracy: 0.4865\n",
      "Epoch 76/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9130e-06 - accuracy: 0.4968 - val_loss: 7.9856e-06 - val_accuracy: 0.4865\n",
      "Epoch 77/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9486e-06 - accuracy: 0.4968 - val_loss: 7.9567e-06 - val_accuracy: 0.4865\n",
      "Epoch 78/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9553e-06 - accuracy: 0.4968 - val_loss: 8.2630e-06 - val_accuracy: 0.4865\n",
      "Epoch 79/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9250e-06 - accuracy: 0.4968 - val_loss: 7.9820e-06 - val_accuracy: 0.4865\n",
      "Epoch 80/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9359e-06 - accuracy: 0.4968 - val_loss: 8.0258e-06 - val_accuracy: 0.4865\n",
      "Epoch 81/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.8886e-06 - accuracy: 0.4968 - val_loss: 8.0244e-06 - val_accuracy: 0.4865\n",
      "Epoch 82/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9880e-06 - accuracy: 0.4968 - val_loss: 8.0006e-06 - val_accuracy: 0.4865\n",
      "Epoch 83/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9691e-06 - accuracy: 0.4968 - val_loss: 8.8137e-06 - val_accuracy: 0.4865\n",
      "Epoch 84/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9333e-06 - accuracy: 0.4968 - val_loss: 7.9513e-06 - val_accuracy: 0.4865\n",
      "Epoch 85/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9325e-06 - accuracy: 0.4968 - val_loss: 7.9514e-06 - val_accuracy: 0.4865\n",
      "Epoch 86/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9340e-06 - accuracy: 0.4968 - val_loss: 8.0487e-06 - val_accuracy: 0.4865\n",
      "Epoch 87/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9243e-06 - accuracy: 0.4968 - val_loss: 8.0825e-06 - val_accuracy: 0.4865\n",
      "Epoch 88/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9264e-06 - accuracy: 0.4968 - val_loss: 8.0282e-06 - val_accuracy: 0.4865\n",
      "Epoch 89/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9060e-06 - accuracy: 0.4968 - val_loss: 8.0654e-06 - val_accuracy: 0.4865\n",
      "Epoch 90/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 8.0028e-06 - accuracy: 0.4968 - val_loss: 7.9537e-06 - val_accuracy: 0.4865\n",
      "Epoch 91/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9093e-06 - accuracy: 0.4968 - val_loss: 8.0019e-06 - val_accuracy: 0.4865\n",
      "Epoch 92/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9432e-06 - accuracy: 0.4968 - val_loss: 8.2062e-06 - val_accuracy: 0.4865\n",
      "Epoch 93/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9361e-06 - accuracy: 0.4968 - val_loss: 7.9516e-06 - val_accuracy: 0.4865\n",
      "Epoch 94/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9414e-06 - accuracy: 0.4968 - val_loss: 8.0288e-06 - val_accuracy: 0.4865\n",
      "Epoch 95/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9471e-06 - accuracy: 0.4968 - val_loss: 8.0349e-06 - val_accuracy: 0.4865\n",
      "Epoch 96/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9326e-06 - accuracy: 0.4968 - val_loss: 8.0681e-06 - val_accuracy: 0.4865\n",
      "Epoch 97/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9826e-06 - accuracy: 0.4968 - val_loss: 8.1627e-06 - val_accuracy: 0.4865\n",
      "Epoch 98/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9266e-06 - accuracy: 0.4968 - val_loss: 8.1136e-06 - val_accuracy: 0.4865\n",
      "Epoch 99/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9392e-06 - accuracy: 0.4968 - val_loss: 8.2579e-06 - val_accuracy: 0.4865\n",
      "Epoch 100/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.9273e-06 - accuracy: 0.4968 - val_loss: 8.2371e-06 - val_accuracy: 0.4865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/independent_batch64_e100_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/independent_batch64_e100_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1814e-06 - accuracy: 0.4992 - val_loss: 7.2187e-06 - val_accuracy: 0.5019\n",
      "Epoch 2/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1937e-06 - accuracy: 0.4992 - val_loss: 7.0401e-06 - val_accuracy: 0.5019\n",
      "Epoch 3/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1918e-06 - accuracy: 0.4992 - val_loss: 7.0196e-06 - val_accuracy: 0.5019\n",
      "Epoch 4/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1900e-06 - accuracy: 0.4992 - val_loss: 7.0726e-06 - val_accuracy: 0.5019\n",
      "Epoch 5/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1819e-06 - accuracy: 0.4992 - val_loss: 7.0865e-06 - val_accuracy: 0.5019\n",
      "Epoch 6/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1901e-06 - accuracy: 0.4992 - val_loss: 7.2590e-06 - val_accuracy: 0.5019\n",
      "Epoch 7/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1872e-06 - accuracy: 0.4992 - val_loss: 7.0221e-06 - val_accuracy: 0.5019\n",
      "Epoch 8/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2089e-06 - accuracy: 0.4992 - val_loss: 7.0227e-06 - val_accuracy: 0.5019\n",
      "Epoch 9/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2153e-06 - accuracy: 0.4992 - val_loss: 7.2816e-06 - val_accuracy: 0.5019\n",
      "Epoch 10/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1896e-06 - accuracy: 0.4992 - val_loss: 7.2104e-06 - val_accuracy: 0.5019\n",
      "Epoch 11/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1979e-06 - accuracy: 0.4992 - val_loss: 7.0677e-06 - val_accuracy: 0.5019\n",
      "Epoch 12/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1937e-06 - accuracy: 0.4992 - val_loss: 7.0280e-06 - val_accuracy: 0.5019\n",
      "Epoch 13/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2356e-06 - accuracy: 0.4992 - val_loss: 7.0660e-06 - val_accuracy: 0.5019\n",
      "Epoch 14/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2195e-06 - accuracy: 0.4992 - val_loss: 7.0199e-06 - val_accuracy: 0.5019\n",
      "Epoch 15/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2222e-06 - accuracy: 0.4992 - val_loss: 7.1473e-06 - val_accuracy: 0.5019\n",
      "Epoch 16/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2144e-06 - accuracy: 0.4992 - val_loss: 7.1016e-06 - val_accuracy: 0.5019\n",
      "Epoch 17/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2074e-06 - accuracy: 0.4992 - val_loss: 7.0500e-06 - val_accuracy: 0.5019\n",
      "Epoch 18/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2064e-06 - accuracy: 0.4992 - val_loss: 7.4534e-06 - val_accuracy: 0.5019\n",
      "Epoch 19/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2112e-06 - accuracy: 0.4992 - val_loss: 7.1192e-06 - val_accuracy: 0.5019\n",
      "Epoch 20/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2011e-06 - accuracy: 0.4992 - val_loss: 7.0190e-06 - val_accuracy: 0.5019\n",
      "Epoch 21/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1903e-06 - accuracy: 0.4992 - val_loss: 7.2473e-06 - val_accuracy: 0.5019\n",
      "Epoch 22/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2044e-06 - accuracy: 0.4992 - val_loss: 7.0210e-06 - val_accuracy: 0.5019\n",
      "Epoch 23/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2050e-06 - accuracy: 0.4992 - val_loss: 7.3217e-06 - val_accuracy: 0.5019\n",
      "Epoch 24/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2227e-06 - accuracy: 0.4992 - val_loss: 7.0640e-06 - val_accuracy: 0.5019\n",
      "Epoch 25/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1956e-06 - accuracy: 0.4992 - val_loss: 7.1786e-06 - val_accuracy: 0.5019\n",
      "Epoch 26/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1744e-06 - accuracy: 0.4992 - val_loss: 7.0522e-06 - val_accuracy: 0.5019\n",
      "Epoch 27/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2050e-06 - accuracy: 0.4992 - val_loss: 7.1053e-06 - val_accuracy: 0.5019\n",
      "Epoch 28/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1865e-06 - accuracy: 0.4992 - val_loss: 7.0186e-06 - val_accuracy: 0.5019\n",
      "Epoch 29/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2024e-06 - accuracy: 0.4992 - val_loss: 7.0352e-06 - val_accuracy: 0.5019\n",
      "Epoch 30/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2154e-06 - accuracy: 0.4992 - val_loss: 7.1311e-06 - val_accuracy: 0.5019\n",
      "Epoch 31/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1621e-06 - accuracy: 0.4992 - val_loss: 7.1304e-06 - val_accuracy: 0.5019\n",
      "Epoch 32/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2052e-06 - accuracy: 0.4992 - val_loss: 7.1817e-06 - val_accuracy: 0.5019\n",
      "Epoch 33/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1736e-06 - accuracy: 0.4992 - val_loss: 7.0324e-06 - val_accuracy: 0.5019\n",
      "Epoch 34/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2209e-06 - accuracy: 0.4992 - val_loss: 7.0684e-06 - val_accuracy: 0.5019\n",
      "Epoch 35/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2077e-06 - accuracy: 0.4992 - val_loss: 7.9660e-06 - val_accuracy: 0.5019\n",
      "Epoch 36/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2142e-06 - accuracy: 0.4992 - val_loss: 7.1475e-06 - val_accuracy: 0.5019\n",
      "Epoch 37/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1855e-06 - accuracy: 0.4992 - val_loss: 7.0405e-06 - val_accuracy: 0.5019\n",
      "Epoch 38/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2142e-06 - accuracy: 0.4992 - val_loss: 7.0187e-06 - val_accuracy: 0.5019\n",
      "Epoch 39/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2405e-06 - accuracy: 0.4992 - val_loss: 7.0255e-06 - val_accuracy: 0.5019\n",
      "Epoch 40/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2108e-06 - accuracy: 0.4992 - val_loss: 7.4386e-06 - val_accuracy: 0.5019\n",
      "Epoch 41/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1964e-06 - accuracy: 0.4992 - val_loss: 7.0472e-06 - val_accuracy: 0.5019\n",
      "Epoch 42/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2189e-06 - accuracy: 0.4992 - val_loss: 7.0447e-06 - val_accuracy: 0.5019\n",
      "Epoch 43/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1768e-06 - accuracy: 0.4992 - val_loss: 7.0842e-06 - val_accuracy: 0.5019\n",
      "Epoch 44/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2116e-06 - accuracy: 0.4992 - val_loss: 7.0777e-06 - val_accuracy: 0.5019\n",
      "Epoch 45/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2276e-06 - accuracy: 0.4992 - val_loss: 7.0186e-06 - val_accuracy: 0.5019\n",
      "Epoch 46/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2039e-06 - accuracy: 0.4992 - val_loss: 7.0257e-06 - val_accuracy: 0.5019\n",
      "Epoch 47/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2072e-06 - accuracy: 0.4992 - val_loss: 7.1628e-06 - val_accuracy: 0.5019\n",
      "Epoch 48/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1949e-06 - accuracy: 0.4992 - val_loss: 7.1506e-06 - val_accuracy: 0.5019\n",
      "Epoch 49/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2172e-06 - accuracy: 0.4992 - val_loss: 7.0669e-06 - val_accuracy: 0.5019\n",
      "Epoch 50/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1891e-06 - accuracy: 0.4992 - val_loss: 7.0209e-06 - val_accuracy: 0.5019\n",
      "Epoch 51/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2220e-06 - accuracy: 0.4992 - val_loss: 7.1385e-06 - val_accuracy: 0.5019\n",
      "Epoch 52/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1891e-06 - accuracy: 0.4992 - val_loss: 7.0782e-06 - val_accuracy: 0.5019\n",
      "Epoch 53/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2031e-06 - accuracy: 0.4992 - val_loss: 7.0323e-06 - val_accuracy: 0.5019\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2048e-06 - accuracy: 0.4992 - val_loss: 7.1666e-06 - val_accuracy: 0.5019\n",
      "Epoch 55/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1970e-06 - accuracy: 0.4992 - val_loss: 7.0186e-06 - val_accuracy: 0.5019\n",
      "Epoch 56/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2174e-06 - accuracy: 0.4992 - val_loss: 7.2114e-06 - val_accuracy: 0.5019\n",
      "Epoch 57/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1834e-06 - accuracy: 0.4992 - val_loss: 7.0194e-06 - val_accuracy: 0.5019\n",
      "Epoch 58/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1970e-06 - accuracy: 0.4992 - val_loss: 7.1601e-06 - val_accuracy: 0.5019\n",
      "Epoch 59/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2160e-06 - accuracy: 0.4992 - val_loss: 7.2095e-06 - val_accuracy: 0.5019\n",
      "Epoch 60/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1624e-06 - accuracy: 0.4992 - val_loss: 7.1860e-06 - val_accuracy: 0.5019\n",
      "Epoch 61/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1778e-06 - accuracy: 0.4992 - val_loss: 7.0287e-06 - val_accuracy: 0.5019\n",
      "Epoch 62/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1948e-06 - accuracy: 0.4992 - val_loss: 7.0198e-06 - val_accuracy: 0.5019\n",
      "Epoch 63/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1796e-06 - accuracy: 0.4992 - val_loss: 7.1176e-06 - val_accuracy: 0.5019\n",
      "Epoch 64/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1960e-06 - accuracy: 0.4992 - val_loss: 7.3438e-06 - val_accuracy: 0.5019\n",
      "Epoch 65/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2396e-06 - accuracy: 0.4992 - val_loss: 7.1244e-06 - val_accuracy: 0.5019\n",
      "Epoch 66/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2379e-06 - accuracy: 0.4992 - val_loss: 7.0498e-06 - val_accuracy: 0.5019\n",
      "Epoch 67/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1966e-06 - accuracy: 0.4992 - val_loss: 7.0318e-06 - val_accuracy: 0.5019\n",
      "Epoch 68/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1855e-06 - accuracy: 0.4992 - val_loss: 7.0196e-06 - val_accuracy: 0.5019\n",
      "Epoch 69/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2201e-06 - accuracy: 0.4992 - val_loss: 7.0284e-06 - val_accuracy: 0.5019\n",
      "Epoch 70/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1943e-06 - accuracy: 0.4992 - val_loss: 7.6378e-06 - val_accuracy: 0.5019\n",
      "Epoch 71/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1859e-06 - accuracy: 0.4992 - val_loss: 7.0186e-06 - val_accuracy: 0.5019\n",
      "Epoch 72/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2190e-06 - accuracy: 0.4992 - val_loss: 7.0976e-06 - val_accuracy: 0.5019\n",
      "Epoch 73/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1836e-06 - accuracy: 0.4992 - val_loss: 7.0259e-06 - val_accuracy: 0.5019\n",
      "Epoch 74/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1933e-06 - accuracy: 0.4992 - val_loss: 7.0203e-06 - val_accuracy: 0.5019\n",
      "Epoch 75/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1751e-06 - accuracy: 0.4992 - val_loss: 7.0192e-06 - val_accuracy: 0.5019\n",
      "Epoch 76/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1904e-06 - accuracy: 0.4992 - val_loss: 7.0504e-06 - val_accuracy: 0.5019\n",
      "Epoch 77/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1816e-06 - accuracy: 0.4992 - val_loss: 7.1340e-06 - val_accuracy: 0.5019\n",
      "Epoch 78/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1883e-06 - accuracy: 0.4992 - val_loss: 7.0565e-06 - val_accuracy: 0.5019\n",
      "Epoch 79/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1950e-06 - accuracy: 0.4992 - val_loss: 7.2283e-06 - val_accuracy: 0.5019\n",
      "Epoch 80/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1921e-06 - accuracy: 0.4992 - val_loss: 7.1056e-06 - val_accuracy: 0.5019\n",
      "Epoch 81/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2018e-06 - accuracy: 0.4992 - val_loss: 7.0394e-06 - val_accuracy: 0.5019\n",
      "Epoch 82/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2198e-06 - accuracy: 0.4992 - val_loss: 7.0700e-06 - val_accuracy: 0.5019\n",
      "Epoch 83/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2212e-06 - accuracy: 0.4992 - val_loss: 7.0191e-06 - val_accuracy: 0.5019\n",
      "Epoch 84/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2022e-06 - accuracy: 0.4992 - val_loss: 7.0198e-06 - val_accuracy: 0.5019\n",
      "Epoch 85/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2274e-06 - accuracy: 0.4992 - val_loss: 7.3390e-06 - val_accuracy: 0.5019\n",
      "Epoch 86/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2035e-06 - accuracy: 0.4992 - val_loss: 7.0643e-06 - val_accuracy: 0.5019\n",
      "Epoch 87/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1752e-06 - accuracy: 0.4992 - val_loss: 7.0186e-06 - val_accuracy: 0.5019\n",
      "Epoch 88/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2276e-06 - accuracy: 0.4992 - val_loss: 7.7390e-06 - val_accuracy: 0.5019\n",
      "Epoch 89/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1728e-06 - accuracy: 0.4992 - val_loss: 7.1227e-06 - val_accuracy: 0.5019\n",
      "Epoch 90/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2082e-06 - accuracy: 0.4992 - val_loss: 7.0222e-06 - val_accuracy: 0.5019\n",
      "Epoch 91/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1789e-06 - accuracy: 0.4992 - val_loss: 7.1070e-06 - val_accuracy: 0.5019\n",
      "Epoch 92/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2423e-06 - accuracy: 0.4992 - val_loss: 7.0205e-06 - val_accuracy: 0.5019\n",
      "Epoch 93/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2006e-06 - accuracy: 0.4992 - val_loss: 7.2787e-06 - val_accuracy: 0.5019\n",
      "Epoch 94/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2150e-06 - accuracy: 0.4992 - val_loss: 7.1595e-06 - val_accuracy: 0.5019\n",
      "Epoch 95/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1858e-06 - accuracy: 0.4992 - val_loss: 7.0306e-06 - val_accuracy: 0.5019\n",
      "Epoch 96/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2195e-06 - accuracy: 0.4992 - val_loss: 7.1760e-06 - val_accuracy: 0.5019\n",
      "Epoch 97/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1822e-06 - accuracy: 0.4992 - val_loss: 7.0219e-06 - val_accuracy: 0.5019\n",
      "Epoch 98/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.1906e-06 - accuracy: 0.4992 - val_loss: 7.0989e-06 - val_accuracy: 0.5019\n",
      "Epoch 99/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2047e-06 - accuracy: 0.4992 - val_loss: 7.1481e-06 - val_accuracy: 0.5019\n",
      "Epoch 100/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.2240e-06 - accuracy: 0.4992 - val_loss: 7.0956e-06 - val_accuracy: 0.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/independent_batch64_e100_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/independent_batch64_e100_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.0085e-06 - accuracy: 0.5024 - val_loss: 6.9842e-06 - val_accuracy: 0.4858\n",
      "Epoch 2/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 6.9811e-06 - accuracy: 0.5024 - val_loss: 6.8585e-06 - val_accuracy: 0.4858\n",
      "Epoch 3/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 7.0020e-06 - accuracy: 0.5024 - val_loss: 6.9289e-06 - val_accuracy: 0.4858\n",
      "Epoch 4/100\n",
      "801/801 [==============================] - 11s 14ms/step - loss: 6.9923e-06 - accuracy: 0.5024 - val_loss: 6.8630e-06 - val_accuracy: 0.4858\n",
      "Epoch 5/100\n",
      "801/801 [==============================] - 10s 13ms/step - loss: 7.0008e-06 - accuracy: 0.5024 - val_loss: 7.1504e-06 - val_accuracy: 0.4858\n",
      "Epoch 6/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 6.9909e-06 - accuracy: 0.5024 - val_loss: 7.2029e-06 - val_accuracy: 0.4858\n",
      "Epoch 7/100\n",
      "801/801 [==============================] - 13s 17ms/step - loss: 7.0136e-06 - accuracy: 0.5024 - val_loss: 7.2163e-06 - val_accuracy: 0.4858\n",
      "Epoch 8/100\n",
      "757/801 [===========================>..] - ETA: 0s - loss: 7.0442e-06 - accuracy: 0.5025"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m      6\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindependent_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(batch_size) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_e\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epochs) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)\n\u001b[0;32m----> 8\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trains\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tests\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/models/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "for i in range(x.shape[2]):\n",
    "    model_name = \"independent_batch\" + str(batch_size) + \"_e\" + str(epochs) + \"_\" + str(i)\n",
    "\n",
    "    history = model.fit(x_train, y_trains[i],\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_tests[i]))\n",
    "\n",
    "    model.save(\"../data/models/\" + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
