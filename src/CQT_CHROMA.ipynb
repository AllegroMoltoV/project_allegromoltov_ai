{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/allegro/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Reading package lists... Done\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "/bin/bash: /home/allegro/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "/bin/bash: /home/allegro/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: scipy in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scipy) (1.23.5)\n",
      "/bin/bash: /home/allegro/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: scikit-learn in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn) (1.10.1)\n",
      "/bin/bash: /home/allegro/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: librosa in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.2.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.0.4)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (4.5.0)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (0.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: setuptools in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (65.6.3)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from pooch>=1.0->librosa) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from pooch>=1.0->librosa) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from pooch>=1.0->librosa) (23.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/allegro/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "# 環境構築\n",
    "\n",
    "!apt-get update\n",
    "!apt-get install -y libsndfile1-dev\n",
    "!pip install scipy\n",
    "!pip install scikit-learn\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/out/clips.wav exists.\n",
      "creating ../data/arrays/c81920_s40960_f32_clips.npy ...\n"
     ]
    }
   ],
   "source": [
    "# clips 作成\n",
    "\n",
    "SAMPLING_RATE = 44100 # 変更不可\n",
    "\n",
    "clip_size = 81920 # 楽曲を再構築するパーツ1つあたりの大きさ\n",
    "step_size = 40960 # clip をずらすときの大きさ\n",
    "window_size = 10240 # CQT_CHROMA を取得するのに使用するサンプル数\n",
    "hop_size = 640 # window をずらすときの大きさ\n",
    "\n",
    "from scipy.io.wavfile import read, write\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import sys\n",
    "\n",
    "if os.path.isfile(\"../data/out/clips.wav\"):\n",
    "    print(\"../data/out/clips.wav exists.\")\n",
    "    files = [\"../data/out/clips.wav\"]\n",
    "else:\n",
    "    # clips.npy をもとにデータを作成する \n",
    "    if os.path.isfile(\"../data/arrays/clips.npy\"):\n",
    "        print(\"loading ../data/arrays/clips.npy ...\")\n",
    "        clips = np.load(\"../data/arrays/clips.npy\")\n",
    "        print(\"creating ../data/out/clips.wav ...\")\n",
    "        write(\"../data/out/clips.wav\", SAMPLING_RATE, clips.reshape((clips.shape[0] * clips.shape[1], )))\n",
    "        files = [\"../data/out/clips.wav\"]\n",
    "        \n",
    "    # clips,npy がないとき /data/wav44100 内の WAV ファイルを参照する\n",
    "    else:\n",
    "        files = glob.glob(\"../data/wav44100/*.wav\")\n",
    "        #files = [\"../data/wav44100/3DEmbodimentFromLines.wav\"] # デバッグ用 \n",
    "        \n",
    "if len(files) == 0:\n",
    "    print(\"WAV ファイルが見つかりませんでした。\")\n",
    "    sys.exit(1)\n",
    "        \n",
    "clips_filename = \"../data/arrays/c\" + str(clip_size) + \"_s\" + str(step_size) + \"_f32_clips\"\n",
    "\n",
    "if os.path.isfile(clips_filename + \".npy\"):\n",
    "    print(\"loading \" + clips_filename + \".npy ...\")\n",
    "    clips = np.load(clips_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + clips_filename + \".npy ...\")\n",
    "    raw_data_list = [librosa.load(file, sr=SAMPLING_RATE)[0] for file in files] # 左の音だけ使う\n",
    "\n",
    "    clips = np.zeros((0, clip_size), dtype=np.float32)\n",
    "    for raw_data in raw_data_list:\n",
    "        tmp = [raw_data[i:i + clip_size] for i in range(0, len(raw_data) - clip_size, step_size)]\n",
    "        clips = np.vstack((clips, np.array(tmp)))\n",
    "    np.save(clips_filename, clips)\n",
    "\n",
    "print(\"The clip array has \" + str(clips.shape[0]) + \" clips.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cqt 作成\n",
    "\n",
    "n_bins = 84\n",
    "\n",
    "cqt_filename = clips_filename + \"_w\" + str(window_size) + \"_h\" + str(hop_size) + \"_cqts\"\n",
    "\n",
    "if os.path.isfile(cqt_filename + \".npy\"):\n",
    "    print(\"loading \" + cqt_filename + \".npy ...\")\n",
    "    cqts = np.load(cqt_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + cqt_filename + \".npy ...\")\n",
    "    num = 0\n",
    "    for clip in clips:\n",
    "        print(\"cqt progress: clip \" + str(num + 1) + \" / \" + str(len(clips)))\n",
    "        \n",
    "        tmp_cqt = librosa.cqt(clip, sr=SAMPLING_RATE, hop_length=hop_size, n_bins=n_bins)\n",
    "        tmp_cqt = tmp_cqt.reshape((1, tmp_cqt.shape[0], tmp_cqt.shape[1]))\n",
    "        \n",
    "        if num == 0:\n",
    "            cqts = tmp_cqt\n",
    "        else:\n",
    "            cqts = np.vstack((cqts, tmp_cqt))\n",
    "            \n",
    "        num += 1\n",
    "\n",
    "    np.save(cqt_filename, cqts)\n",
    "    \n",
    "print(\"The cqt array has \" + str(cqts.shape[0]) + \" cqts.\")\n",
    "print(\"cqts.shape: \" + str(cqts.shape))\n",
    "print(\"Type(cqts[0][0][0]): \" + str(type(cqts[0][0][0])))\n",
    "print(\"np.max(cqts[0][0]): \" + str(np.max(cqts[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cqt_choroma 作成\n",
    "\n",
    "def Preprocessing(array):\n",
    "    array = np.abs(array)\n",
    "    array = np.log(array + 1)\n",
    "    array = array / np.log(np.finfo(np.float32).max)\n",
    "    array = array.T\n",
    "    return array\n",
    "\n",
    "cqt_chroma_filename = clips_filename + \"_w\" + str(window_size) + \"_h\" + str(hop_size) + \"_cqt_chromas\"\n",
    "\n",
    "if os.path.isfile(cqt_chroma_filename + \".npy\"):\n",
    "    print(\"loading \" + cqt_chroma_filename + \".npy ...\")\n",
    "    cqt_chromas= np.load(cqt_chroma_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + cqt_chroma_filename + \".npy ...\")\n",
    "    num = 0\n",
    "    for cqt in cqts:\n",
    "        print(\"cqt_chroma progress: clip \" + str(num + 1) + \" / \" + str(len(cqts)))\n",
    "        \n",
    "        tmp_cqt_chroma = librosa.feature.chroma_cqt(C=cqt, sr=SAMPLING_RATE)\n",
    "        tmp_cqt_chroma = Preprocessing(tmp_cqt_chroma)\n",
    "        tmp_cqt_chroma = tmp_cqt_chroma.reshape((1, tmp_cqt_chroma.shape[0], tmp_cqt_chroma.shape[1]))\n",
    "        \n",
    "        if num == 0:\n",
    "            cqt_chromas = tmp_cqt_chroma\n",
    "        else:\n",
    "            cqt_chromas = np.vstack((cqt_chromas, tmp_cqt_chroma))\n",
    "            \n",
    "        num += 1\n",
    "\n",
    "    np.save(cqt_chroma_filename, cqt_chromas)\n",
    "    \n",
    "print(\"The cqt_chroma array has \" + str(cqt_chromas.shape[0]) + \" cqt_chromas.\")\n",
    "print(\"cqt_chromas.shape: \" + str(cqt_chromas.shape)) # clip 番号、window 番号、 chroma 番号 になる\n",
    "print(\"Type(cqt_chromas[0][0][0]): \" + str(type(cqt_chromas[0][0][0])))\n",
    "print(\"np.max(cqt_chromas[0][0]): \" + str(np.max(cqt_chromas[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_norm 作成\n",
    "\n",
    "num_divide = 2\n",
    "\n",
    "max_norm_filename = clips_filename + \"_d\" + str(num_divide) + \"_max_norms\"\n",
    "\n",
    "if os.path.isfile(max_norm_filename + \".npy\"):\n",
    "    print(\"loading \" + max_norm_filename + \".npy ...\")\n",
    "    max_norms= np.load(max_norm_filename + \".npy\")\n",
    "else:\n",
    "    print(\"creating \" + max_norm_filename + \".npy ...\")\n",
    "    num = 0\n",
    "    for clip in clips:\n",
    "        print(\"max_norm progress: clip \" + str(num + 1) + \" / \" + str(len(clips)))\n",
    "        max_norm = [np.max(clip[int((i / num_divide) * len(clip)):int(((i + 1) / num_divide) * len(clip))] ** 2) for i in range(num_divide)]\n",
    "    \n",
    "        if num == 0:\n",
    "            max_norms = np.array(max_norm)\n",
    "        else:\n",
    "            max_norms = np.vstack((max_norms, np.array(max_norm)))\n",
    "        num += 1\n",
    "        \n",
    "    np.save(max_norm_filename, max_norms)\n",
    "    \n",
    "print(\"The max_norm array has \" + str(max_norms.shape[0]) + \" max_norms.\")\n",
    "print(\"max_norms.shape: \" + str(max_norms.shape))\n",
    "print(\"Type(max_norms[0][0]): \" + str(type(max_norms[0][0])))\n",
    "print(\"np.max(max_norms[0]): \" + str(np.max(max_norms[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとテストデータに分ける\n",
    "\n",
    "def normalize(array):\n",
    "    if (np.sum(array) == 0):\n",
    "        return array\n",
    "    else:\n",
    "        return array / np.sum(array)\n",
    "    \n",
    "cqt_chroma_sum_threshold = 0.01 # 次の window の sum が閾値に満たないときに除外します\n",
    "test_data_rate = 0.1\n",
    "weight = 0.01 # max_norm の重み\n",
    "\n",
    "window_num_per_clip = cqt_chromas.shape[1]\n",
    "\n",
    "cqt_chromas = np.array([np.hstack((cqt_chromas[i], np.repeat(np.array([max_norms[i]]), cqt_chromas.shape[1], axis=0) * weight)) for i in range(len(max_norms))])\n",
    "cqt_chromas = np.concatenate([cqt_chromas[:-1, :, :], cqt_chromas[1:, 0, :].reshape(cqt_chromas.shape[0] - 1, 1, cqt_chromas.shape[2])], 1)\n",
    "\n",
    "p = np.random.permutation(len(cqt_chromas))\n",
    "cqt_chromas = cqt_chromas[p]\n",
    "clips = clips[p]\n",
    "\n",
    "x = np.delete(cqt_chromas, np.where(np.sum(cqt_chromas[:,-1,:], axis=1) < cqt_chroma_sum_threshold)[0], axis=0)\n",
    "\n",
    "x_test = np.apply_along_axis(normalize, 2, x[:int(x.shape[0] * test_data_rate), :window_num_per_clip, :].reshape(int(x.shape[0] * test_data_rate), window_num_per_clip, x.shape[2], 1))\n",
    "x_train = np.apply_along_axis(normalize, 2, x[int(x.shape[0] * test_data_rate):, :window_num_per_clip, :].reshape(x.shape[0] - int(x.shape[0] * test_data_rate), window_num_per_clip, x.shape[2], 1))\n",
    "y_test =  np.apply_along_axis(normalize, 1, x[:int(x.shape[0] * test_data_rate), window_num_per_clip, :])\n",
    "y_train = np.apply_along_axis(normalize, 1, x[int(x.shape[0] * test_data_rate):, window_num_per_clip, :])\n",
    "\n",
    "print(\"x_train.shape: \" + str(x_train.shape))\n",
    "print(\"x_test.shape: \" + str(x_test.shape))\n",
    "print(\"y_train.shape: \" + str(y_train.shape))\n",
    "print(\"y_test.shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # 精度の履歴をプロット\n",
    "    plt.plot(history.history['accuracy'],\"o-\",label=\"accuracy\")\n",
    "    plt.plot(history.history['val_accuracy'],\"o-\",label=\"val_acc\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    " \n",
    "    # 損失の履歴をプロット\n",
    "    plt.plot(history.history['loss'],\"o-\",label=\"loss\",)\n",
    "    plt.plot(history.history['val_loss'],\"o-\",label=\"val_loss\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル作成\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, Input, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "learning_rate = 0.001\n",
    " \n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(32, (3, 1), activation=\"relu\", input_shape=(window_num_per_clip, cqt_chromas.shape[2], 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, (3, 1), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(128, (3, 1), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(256, (3, 1), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=cqt_chromas.shape[2]))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=learning_rate),metrics=['accuracy'])\n",
    "\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "model_name = \"cqt_chroma_batch\" + str(batch_size) + \"_e\" + str(epochs)\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "model.save(\"../data/models/\" + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 遷移のプロット\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 楽曲の出力\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.models import load_model\n",
    "import soundfile as sf\n",
    "\n",
    "model = load_model(\"../data/models/\" + model_name)\n",
    "file_name = \"out_\" + model_name\n",
    "num_clips = 10\n",
    "\n",
    "def add_fade(x, fadetime, sr):\n",
    "    ft_len = int(fadetime*sr)\n",
    "    r = np.arange(0, ft_len)*np.pi/ft_len\n",
    "    w_fo = (0.5+0.5*np.cos(r))**0.5\n",
    "    w_fi = (0.5-0.5*np.cos(r))**0.5\n",
    "    \n",
    "    x[0:ft_len]        *= w_fi\n",
    "    x[clip_size-ft_len::] *= w_fo\n",
    "    return x\n",
    "\n",
    "def gen_xfade(x_pre, x_next, fadetime, sr):\n",
    "    ft_len = int(fadetime*sr)\n",
    "    if x_pre is None:\n",
    "        xfade = x_next\n",
    "    else:\n",
    "        x_pre_begin = x_pre[:x_pre.shape[0] - ft_len]\n",
    "        x_pre_end = x_pre[x_pre.shape[0] - ft_len:]\n",
    "        x_pre_len = clip_size\n",
    "        x_next_len = clip_size\n",
    "        x_pre_len -= ft_len\n",
    "        x_next_len -= ft_len\n",
    "        xfade = np.concatenate((x_pre_begin, np.concatenate((x_pre_end, np.zeros(x_next_len))) + x_next))\n",
    "    return xfade\n",
    "\n",
    "def create_music(fname):\n",
    "    first_index = np.random.randint(0, len(cqt_chromas))\n",
    "    predict_index = first_index\n",
    "    out = None\n",
    "    \n",
    "    for i in range(num_clips):\n",
    "        print(\"-- generate \" + str(i + 1) + \" / \" + str(num_clips))\n",
    "        predict = model.predict(np.array([cqt_chromas[predict_index, :-1]]))\n",
    "\n",
    "        index = 0\n",
    "        similar_index = 0\n",
    "        cos_sim = -1\n",
    "        for cqt_chroma in cqt_chromas[:, 0:1]:\n",
    "            tmp_sim = cosine_similarity(predict, cqt_chroma) \n",
    "            if tmp_sim > cos_sim:\n",
    "                cos_sim = tmp_sim\n",
    "                similar_index = index\n",
    "            index += 1\n",
    "\n",
    "        print(\"cos_sim: \" + str(cos_sim))\n",
    "        print(\"predict: \" + str(predict))\n",
    "        print(\"cqt_chromas[similar_index]: \" + str(cqt_chromas[similar_index, 0]))\n",
    "        print(\"similar_index: \" + str(similar_index))\n",
    "        print(\"--\")\n",
    "\n",
    "        predict_index = similar_index\n",
    "\n",
    "        tmp = add_fade(clips[predict_index], 0.1, SAMPLING_RATE)\n",
    "        out = gen_xfade(out, tmp, 0.1, SAMPLING_RATE)\n",
    "    \n",
    "    \n",
    "    sf.write(fname, out, SAMPLING_RATE, subtype=\"PCM_16\")\n",
    "\n",
    "fname = \"../data/out/\" + file_name + \"_1.wav\"\n",
    "print(\"creating \" + fname + \" ...\")\n",
    "create_music(fname)\n",
    "\n",
    "fname = \"../data/out/\" + file_name + \"_2.wav\"\n",
    "print(\"creating \" + fname + \" ...\")\n",
    "create_music(fname)\n",
    "\n",
    "fname = \"../data/out/\" + file_name + \"_3.wav\"\n",
    "print(\"creating \" + fname + \" ...\")\n",
    "create_music(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
